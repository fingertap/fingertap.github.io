<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content='最近一直在研究LLM中的强化学习，其中KL散度作为一个关键的方法，通常用于作为正则，要求优化分布距离参考分布不能太远。John Schulman的博客里讨论K2和K3，作为两种能保证KL估计在所有采样点处均非负的估计子。\n然而这两个估计子都不够鲁棒，K2自不用说，方差特别大。广泛被大家采用的K3其实也有很大的问题，原因是估计中存在$\\frac{p(x)}{q(x)}$项，当$q(x)$很小时这个值会非常大。这导致我们的优化过程中会不时出现很大的spike，容易带崩训练。\n因此我们需要构造一个不会引起spike的KL估计子，这个估计子中不能包含$p(x)/q(x)$项。同时，我们也需要这个KL估计子是非负的，否则模型将可以很容易地hack这个KL。\n直接上结论，我提出一个K4估计子\n$$ K4(x; p, q)=\\log \\left(p^2(x) - 2p(x)q(x) + 2q^2(x)\\right) - 2\\log q(x) \\tag{1} $$这个算子的性能全方位优于已有算子，表现为具有更低的偏差，更低的方差，保证非负，保证没有spike。我用John的代码测试了K4：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import torch.distributions as dis import pandas as pd p = dis.Normal(loc=0.5, scale=1.2) q = dis.Normal(loc=1.3, scale=2.5) x = q.sample(sample_shape=(10_000_000,)) truekl = dis.kl_divergence(p, q) print("true", truekl) logr = p.log_prob(x) - q.log_prob(x) k1 = -logr k2 = logr ** 2 / 2 k3 = (logr.exp() - 1) - logr px = p.log_prob(x).exp() qx = q.log_prob(x).exp() k4 = (px**2 - 2*px*qx+2*qx**2).log() - 2 * q.log_prob(x) results = {} kl_names = ["k1", "k2", "k3", "k4"] kl_estimators = [k1, k2, k3, k4] for k, kl_name in zip(kl_estimators, kl_names): bias = (k.mean() - truekl) / truekl std = k.std() / truekl min = k.min() max = k.max() results[kl_name] = { "bias": bias.item(), "std": std.item(), "min": min.item(), "max": max.item() } pd.DataFrame(results).T 结果：\n'><title>一种新的KL散度估计</title>
<link rel=canonical href=https://fingertap.github.io/p/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84kl%E6%95%A3%E5%BA%A6%E4%BC%B0%E8%AE%A1/><link rel=stylesheet href=/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="一种新的KL散度估计"><meta property='og:description' content='最近一直在研究LLM中的强化学习，其中KL散度作为一个关键的方法，通常用于作为正则，要求优化分布距离参考分布不能太远。John Schulman的博客里讨论K2和K3，作为两种能保证KL估计在所有采样点处均非负的估计子。\n然而这两个估计子都不够鲁棒，K2自不用说，方差特别大。广泛被大家采用的K3其实也有很大的问题，原因是估计中存在$\\frac{p(x)}{q(x)}$项，当$q(x)$很小时这个值会非常大。这导致我们的优化过程中会不时出现很大的spike，容易带崩训练。\n因此我们需要构造一个不会引起spike的KL估计子，这个估计子中不能包含$p(x)/q(x)$项。同时，我们也需要这个KL估计子是非负的，否则模型将可以很容易地hack这个KL。\n直接上结论，我提出一个K4估计子\n$$ K4(x; p, q)=\\log \\left(p^2(x) - 2p(x)q(x) + 2q^2(x)\\right) - 2\\log q(x) \\tag{1} $$这个算子的性能全方位优于已有算子，表现为具有更低的偏差，更低的方差，保证非负，保证没有spike。我用John的代码测试了K4：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import torch.distributions as dis import pandas as pd p = dis.Normal(loc=0.5, scale=1.2) q = dis.Normal(loc=1.3, scale=2.5) x = q.sample(sample_shape=(10_000_000,)) truekl = dis.kl_divergence(p, q) print("true", truekl) logr = p.log_prob(x) - q.log_prob(x) k1 = -logr k2 = logr ** 2 / 2 k3 = (logr.exp() - 1) - logr px = p.log_prob(x).exp() qx = q.log_prob(x).exp() k4 = (px**2 - 2*px*qx+2*qx**2).log() - 2 * q.log_prob(x) results = {} kl_names = ["k1", "k2", "k3", "k4"] kl_estimators = [k1, k2, k3, k4] for k, kl_name in zip(kl_estimators, kl_names): bias = (k.mean() - truekl) / truekl std = k.std() / truekl min = k.min() max = k.max() results[kl_name] = { "bias": bias.item(), "std": std.item(), "min": min.item(), "max": max.item() } pd.DataFrame(results).T 结果：\n'><meta property='og:url' content='https://fingertap.github.io/p/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84kl%E6%95%A3%E5%BA%A6%E4%BC%B0%E8%AE%A1/'><meta property='og:site_name' content='张晗的随笔'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='Machine Learning'><meta property='article:tag' content='Math'><meta property='article:published_time' content='2025-03-07T22:55:45+08:00'><meta property='article:modified_time' content='2025-03-07T22:55:45+08:00'><meta property='og:image' content='https://fingertap.github.io/p/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84kl%E6%95%A3%E5%BA%A6%E4%BC%B0%E8%AE%A1/cover.png'><meta name=twitter:title content="一种新的KL散度估计"><meta name=twitter:description content='最近一直在研究LLM中的强化学习，其中KL散度作为一个关键的方法，通常用于作为正则，要求优化分布距离参考分布不能太远。John Schulman的博客里讨论K2和K3，作为两种能保证KL估计在所有采样点处均非负的估计子。\n然而这两个估计子都不够鲁棒，K2自不用说，方差特别大。广泛被大家采用的K3其实也有很大的问题，原因是估计中存在$\\frac{p(x)}{q(x)}$项，当$q(x)$很小时这个值会非常大。这导致我们的优化过程中会不时出现很大的spike，容易带崩训练。\n因此我们需要构造一个不会引起spike的KL估计子，这个估计子中不能包含$p(x)/q(x)$项。同时，我们也需要这个KL估计子是非负的，否则模型将可以很容易地hack这个KL。\n直接上结论，我提出一个K4估计子\n$$ K4(x; p, q)=\\log \\left(p^2(x) - 2p(x)q(x) + 2q^2(x)\\right) - 2\\log q(x) \\tag{1} $$这个算子的性能全方位优于已有算子，表现为具有更低的偏差，更低的方差，保证非负，保证没有spike。我用John的代码测试了K4：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import torch.distributions as dis import pandas as pd p = dis.Normal(loc=0.5, scale=1.2) q = dis.Normal(loc=1.3, scale=2.5) x = q.sample(sample_shape=(10_000_000,)) truekl = dis.kl_divergence(p, q) print("true", truekl) logr = p.log_prob(x) - q.log_prob(x) k1 = -logr k2 = logr ** 2 / 2 k3 = (logr.exp() - 1) - logr px = p.log_prob(x).exp() qx = q.log_prob(x).exp() k4 = (px**2 - 2*px*qx+2*qx**2).log() - 2 * q.log_prob(x) results = {} kl_names = ["k1", "k2", "k3", "k4"] kl_estimators = [k1, k2, k3, k4] for k, kl_name in zip(kl_estimators, kl_names): bias = (k.mean() - truekl) / truekl std = k.std() / truekl min = k.min() max = k.max() results[kl_name] = { "bias": bias.item(), "std": std.item(), "min": min.item(), "max": max.item() } pd.DataFrame(results).T 结果：\n'><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://fingertap.github.io/p/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84kl%E6%95%A3%E5%BA%A6%E4%BC%B0%E8%AE%A1/cover.png'><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_ce70c8f8535541a2.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🇨🇳</span></figure><div class=site-meta><h1 class=site-name><a href=/>张晗的随笔</a></h1><h2 class=site-description>看风景 > 爬上山顶</h2></div></header><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/about-me/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>About Me</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><ol><li><a href=#citation>Citation</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84kl%E6%95%A3%E5%BA%A6%E4%BC%B0%E8%AE%A1/><img src=/p/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84kl%E6%95%A3%E5%BA%A6%E4%BC%B0%E8%AE%A1/cover_hu_4703ed12d1987494.png srcset="/p/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84kl%E6%95%A3%E5%BA%A6%E4%BC%B0%E8%AE%A1/cover_hu_4703ed12d1987494.png 800w, /p/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84kl%E6%95%A3%E5%BA%A6%E4%BC%B0%E8%AE%A1/cover_hu_903e468636f86f3f.png 1600w" width=800 height=800 loading=lazy alt="Featured image of post 一种新的KL散度估计"></a></div><div class=article-details><header class=article-category><a href=/categories/machine-learning/>Machine Learning</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84kl%E6%95%A3%E5%BA%A6%E4%BC%B0%E8%AE%A1/>一种新的KL散度估计</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Mar 07, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 2 分钟</time></div></footer></div></header><section class=article-content><p>最近一直在研究LLM中的强化学习，其中KL散度作为一个关键的方法，通常用于作为正则，要求优化分布距离参考分布不能太远。<a class=link href=http://joschu.net/blog/kl-approx.html target=_blank rel=noopener>John Schulman的博客</a>里讨论K2和K3，作为两种能保证KL估计在所有采样点处均非负的估计子。</p><p>然而这两个估计子都不够鲁棒，K2自不用说，方差特别大。广泛被大家采用的K3其实也有很大的问题，原因是估计中存在$\frac{p(x)}{q(x)}$项，当$q(x)$很小时这个值会非常大。这导致我们的优化过程中会不时出现很大的spike，容易带崩训练。</p><p>因此我们需要构造一个不会引起spike的KL估计子，这个估计子中不能包含$p(x)/q(x)$项。同时，我们也需要这个KL估计子是非负的，否则模型将可以很容易地hack这个KL。</p><p>直接上结论，我提出一个K4估计子</p>$$
K4(x; p, q)=\log \left(p^2(x) - 2p(x)q(x) + 2q^2(x)\right) - 2\log q(x) \tag{1}
$$<p>这个算子的性能全方位优于已有算子，表现为具有更低的偏差，更低的方差，保证非负，保证没有spike。我用John的代码测试了K4：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.distributions</span> <span class=k>as</span> <span class=nn>dis</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>p</span> <span class=o>=</span> <span class=n>dis</span><span class=o>.</span><span class=n>Normal</span><span class=p>(</span><span class=n>loc</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mf>1.2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>q</span> <span class=o>=</span> <span class=n>dis</span><span class=o>.</span><span class=n>Normal</span><span class=p>(</span><span class=n>loc</span><span class=o>=</span><span class=mf>1.3</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mf>2.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>q</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=n>sample_shape</span><span class=o>=</span><span class=p>(</span><span class=mi>10_000_000</span><span class=p>,))</span>
</span></span><span class=line><span class=cl><span class=n>truekl</span> <span class=o>=</span> <span class=n>dis</span><span class=o>.</span><span class=n>kl_divergence</span><span class=p>(</span><span class=n>p</span><span class=p>,</span> <span class=n>q</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;true&#34;</span><span class=p>,</span> <span class=n>truekl</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logr</span> <span class=o>=</span> <span class=n>p</span><span class=o>.</span><span class=n>log_prob</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>-</span> <span class=n>q</span><span class=o>.</span><span class=n>log_prob</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>k1</span> <span class=o>=</span> <span class=o>-</span><span class=n>logr</span>
</span></span><span class=line><span class=cl><span class=n>k2</span> <span class=o>=</span> <span class=n>logr</span> <span class=o>**</span> <span class=mi>2</span> <span class=o>/</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=n>k3</span> <span class=o>=</span> <span class=p>(</span><span class=n>logr</span><span class=o>.</span><span class=n>exp</span><span class=p>()</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span> <span class=o>-</span> <span class=n>logr</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>px</span> <span class=o>=</span> <span class=n>p</span><span class=o>.</span><span class=n>log_prob</span><span class=p>(</span><span class=n>x</span><span class=p>)</span><span class=o>.</span><span class=n>exp</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>qx</span> <span class=o>=</span> <span class=n>q</span><span class=o>.</span><span class=n>log_prob</span><span class=p>(</span><span class=n>x</span><span class=p>)</span><span class=o>.</span><span class=n>exp</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>k4</span> <span class=o>=</span> <span class=p>(</span><span class=n>px</span><span class=o>**</span><span class=mi>2</span> <span class=o>-</span> <span class=mi>2</span><span class=o>*</span><span class=n>px</span><span class=o>*</span><span class=n>qx</span><span class=o>+</span><span class=mi>2</span><span class=o>*</span><span class=n>qx</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>log</span><span class=p>()</span> <span class=o>-</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>q</span><span class=o>.</span><span class=n>log_prob</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl><span class=n>kl_names</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;k1&#34;</span><span class=p>,</span> <span class=s2>&#34;k2&#34;</span><span class=p>,</span> <span class=s2>&#34;k3&#34;</span><span class=p>,</span> <span class=s2>&#34;k4&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>kl_estimators</span> <span class=o>=</span> <span class=p>[</span><span class=n>k1</span><span class=p>,</span> <span class=n>k2</span><span class=p>,</span> <span class=n>k3</span><span class=p>,</span> <span class=n>k4</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>kl_name</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>kl_estimators</span><span class=p>,</span> <span class=n>kl_names</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>bias</span> <span class=o>=</span> <span class=p>(</span><span class=n>k</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span> <span class=o>-</span> <span class=n>truekl</span><span class=p>)</span> <span class=o>/</span> <span class=n>truekl</span>
</span></span><span class=line><span class=cl>    <span class=n>std</span> <span class=o>=</span> <span class=n>k</span><span class=o>.</span><span class=n>std</span><span class=p>()</span> <span class=o>/</span> <span class=n>truekl</span>
</span></span><span class=line><span class=cl>    <span class=nb>min</span> <span class=o>=</span> <span class=n>k</span><span class=o>.</span><span class=n>min</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=nb>max</span> <span class=o>=</span> <span class=n>k</span><span class=o>.</span><span class=n>max</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span><span class=p>[</span><span class=n>kl_name</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;bias&#34;</span><span class=p>:</span> <span class=n>bias</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;std&#34;</span><span class=p>:</span> <span class=n>std</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;min&#34;</span><span class=p>:</span> <span class=nb>min</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;max&#34;</span><span class=p>:</span> <span class=nb>max</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl><span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>results</span><span class=p>)</span><span class=o>.</span><span class=n>T</span>
</span></span></code></pre></td></tr></table></div></div><p>结果：</p><div class=table-wrapper><table><thead><tr><th></th><th>bias</th><th>std</th><th>min</th><th>max</th></tr></thead><tbody><tr><td><strong>k1</strong></td><td>1.893368</td><td>6.842822</td><td>-8.004973e-01</td><td>49.598541</td></tr><tr><td><strong>k2</strong></td><td>10.049346</td><td>40.413708</td><td>2.842171e-14</td><td>1230.007690</td></tr><tr><td><strong>k3</strong></td><td>1.892912</td><td>5.611935</td><td>0.000000e+00</td><td>48.598541</td></tr><tr><td><strong>k4</strong></td><td>0.164644</td><td>0.717409</td><td>-2.384186e-07</td><td>0.918155</td></tr></tbody></table></div><details><p>K4在式$(1)$中的形式等价于</p>$$
\log\left\{\left(\frac{p(x)}{q(x)}-1\right)^2+1\right\}
$$<p>这显然是大于0且在$\frac{p(x)}{q(x)}=1$处取得最小值0。</p></details><h3 id=citation>Citation</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>@misc{ZhangBlogKL,
</span></span><span class=line><span class=cl>  author       = {Zhang, Han},
</span></span><span class=line><span class=cl>  title        = {Yet another new {KL} estimator},
</span></span><span class=line><span class=cl>  year         = {2025},
</span></span><span class=line><span class=cl>  howpublished = {Blog post},
</span></span><span class=line><span class=cl>  url          = {https://fingertap.github.io/p/一种新的KL散度估计},
</span></span><span class=line><span class=cl>  urldate      = {2025-03-07}
</span></span><span class=line><span class=cl>}
</span></span></code></pre></td></tr></table></div></div></section><footer class=article-footer><section class=article-tags><a href=/tags/machine-learning/>Machine Learning</a>
<a href=/tags/math/>Math</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%94%B6%E6%95%9B%E5%88%86%E6%9E%90/><div class=article-image><img src=/p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%94%B6%E6%95%9B%E5%88%86%E6%9E%90/cover.0f792aeaf735d1882c7842d7f7a09182_hu_934424ce9ce33e5a.png width=250 height=150 loading=lazy alt="Featured image of post 梯度下降收敛分析" data-hash="md5-D3kq6vc10YgseELX96CRgg=="></div><div class=article-details><h2 class=article-title>梯度下降收敛分析</h2></div></a></article><article class=has-image><a href=/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/><div class=article-image><img src=/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/cover.14e58351554cfa73826426d3e2e1aace_hu_a47d951a9fa767ee.png width=250 height=150 loading=lazy alt="Featured image of post 隐变量模型总结" data-hash="md5-FOWDUVVM+nOCZCbT4uGqzg=="></div><div class=article-details><h2 class=article-title>隐变量模型总结</h2></div></a></article><article class=has-image><a href=/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/><div class=article-image><img src=/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/cover.84d3b9acd81cdce809bf40d9c86bf4b0_hu_2ec8dbcdde98afbe.png width=250 height=150 loading=lazy alt="Featured image of post 从拒绝采样到投机推理" data-hash="md5-hNO5rNgc3OgJv0DZyGv0sA=="></div><div class=article-details><h2 class=article-title>从拒绝采样到投机推理</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2025 张晗的随笔</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>
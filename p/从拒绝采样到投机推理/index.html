<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="这两天看到ICLR 2025的一篇Oral做投机采样和级联模型结合，突然感觉以前拒绝采样的知识都很模糊了，于是有了这篇梳理拒绝采样的文章。\n采样问题 经典的采样问题是说，我希望从某个空间中采样出一些$x$，其采样出来的概率服从一个分布$\\pi(x)$。\n举例来说，如果这个空间是像素空间，分布$\\pi(x)$的概率密度聚集于猫狗照片，那么我们期望从中采样出来的$x$都是一些小猫小狗的照片；如果这个空间是句子空间，分布$\\pi(x)$的概率密度聚集于一些中文语料，那么我们期望从中采样出来的$x$都是一些中文的句子。\n对于一个简单的分布，我们可以用change of variable规则，将均匀分布转换成目标分布。然而，这种方法对于无法积分或者甚至没有解析表达的分布而言是不可行的。对于这样的分布，我们假设我们对于任意$x$，可以计算其概率密度$\\pi(x)$，希望能采样出一系列样本$\\left\\lbrace x_i\\right\\rbrace_{i=1}^N$，使得每个样本被采样到的概率$P\\left(X=x_i\\right)$等于其真实概率$\\pi\\left(x_i\\right)$。\n朴素的拒绝采样 朴素的拒绝采样的做法是给定一个提议分布 $q(x)$ ，将其乘上一个常数$k$以保证在任意 $x$ 处 $kq(x)\\geq\\pi(x)$ 。有了这个条件以后，我们按照这样的拒绝采样流程得到样本：\n从提议分布 $q(x)$ 中采样得到样本$x$， 以概率 $\\frac{\\pi(x)}{k \\cdot q(x)}$ 接受这个样本。 显然对于所有被接受的样本，其被采样的概率是正比与$\\pi(x)$的。然而，如下图所示，所有红色部分都会被拒绝，因此朴素的拒绝采样的样本效率可能会较低，一个更紧的提议分布上界带来的拒绝率越低。\n适应性拒绝采样 朴素的拒绝采样有可能连续出现样本被拒绝的情况。这在目标分布非常尖锐，提议分布无法很紧地包住它时常见（例如上图中2峰变为N峰，提议分布仍然使用高斯时）。适应性的拒绝采样可以有效提高采样效率，降低拒绝率。\n适应性采样保证了不会出现连续被拒绝的样本。其核心思想是将采样的概率质量区域划分为三部分：\n拒绝区域 $q(x)>\\pi(x)$ ，即下图的红色区域。 接受区域 $\\min(q(x), \\pi(x))$ ，即下图的绿色区域。 重采样区域 $\\max(\\pi(x) - q(x), 0)$ ，即下图的蓝色区域。 其中，对于属于重采样区域的样本$x$，其概率密度正比于 $\\max(\\pi(x) - q(x), 0)$ 。具体采样流程如下：\n从提议分布 $q(x)$ 中采样得到样本$x$， 以概率 $\\min\\left(\\frac{\\pi(x)}{q(x)}, 1\\right)$ 接受这个样本（即落在绿色区域即接受）。 若拒绝了此样本$x$，从蓝色区域采样一个样本出来。 适应性拒绝采样可以保证两次采样必然能获得至少一个接受样本 。然而，重采样过程和从原分布采样是类似的，在无法积分的情况下不可行，但是在大语言模型的生成分布是多项分布，因此投机推理中适应性采样恰好合用。\n"><title>从拒绝采样到投机推理</title>
<link rel=canonical href=https://fingertap.github.io/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/><link rel=stylesheet href=/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="从拒绝采样到投机推理"><meta property='og:description' content="这两天看到ICLR 2025的一篇Oral做投机采样和级联模型结合，突然感觉以前拒绝采样的知识都很模糊了，于是有了这篇梳理拒绝采样的文章。\n采样问题 经典的采样问题是说，我希望从某个空间中采样出一些$x$，其采样出来的概率服从一个分布$\\pi(x)$。\n举例来说，如果这个空间是像素空间，分布$\\pi(x)$的概率密度聚集于猫狗照片，那么我们期望从中采样出来的$x$都是一些小猫小狗的照片；如果这个空间是句子空间，分布$\\pi(x)$的概率密度聚集于一些中文语料，那么我们期望从中采样出来的$x$都是一些中文的句子。\n对于一个简单的分布，我们可以用change of variable规则，将均匀分布转换成目标分布。然而，这种方法对于无法积分或者甚至没有解析表达的分布而言是不可行的。对于这样的分布，我们假设我们对于任意$x$，可以计算其概率密度$\\pi(x)$，希望能采样出一系列样本$\\left\\lbrace x_i\\right\\rbrace_{i=1}^N$，使得每个样本被采样到的概率$P\\left(X=x_i\\right)$等于其真实概率$\\pi\\left(x_i\\right)$。\n朴素的拒绝采样 朴素的拒绝采样的做法是给定一个提议分布 $q(x)$ ，将其乘上一个常数$k$以保证在任意 $x$ 处 $kq(x)\\geq\\pi(x)$ 。有了这个条件以后，我们按照这样的拒绝采样流程得到样本：\n从提议分布 $q(x)$ 中采样得到样本$x$， 以概率 $\\frac{\\pi(x)}{k \\cdot q(x)}$ 接受这个样本。 显然对于所有被接受的样本，其被采样的概率是正比与$\\pi(x)$的。然而，如下图所示，所有红色部分都会被拒绝，因此朴素的拒绝采样的样本效率可能会较低，一个更紧的提议分布上界带来的拒绝率越低。\n适应性拒绝采样 朴素的拒绝采样有可能连续出现样本被拒绝的情况。这在目标分布非常尖锐，提议分布无法很紧地包住它时常见（例如上图中2峰变为N峰，提议分布仍然使用高斯时）。适应性的拒绝采样可以有效提高采样效率，降低拒绝率。\n适应性采样保证了不会出现连续被拒绝的样本。其核心思想是将采样的概率质量区域划分为三部分：\n拒绝区域 $q(x)>\\pi(x)$ ，即下图的红色区域。 接受区域 $\\min(q(x), \\pi(x))$ ，即下图的绿色区域。 重采样区域 $\\max(\\pi(x) - q(x), 0)$ ，即下图的蓝色区域。 其中，对于属于重采样区域的样本$x$，其概率密度正比于 $\\max(\\pi(x) - q(x), 0)$ 。具体采样流程如下：\n从提议分布 $q(x)$ 中采样得到样本$x$， 以概率 $\\min\\left(\\frac{\\pi(x)}{q(x)}, 1\\right)$ 接受这个样本（即落在绿色区域即接受）。 若拒绝了此样本$x$，从蓝色区域采样一个样本出来。 适应性拒绝采样可以保证两次采样必然能获得至少一个接受样本 。然而，重采样过程和从原分布采样是类似的，在无法积分的情况下不可行，但是在大语言模型的生成分布是多项分布，因此投机推理中适应性采样恰好合用。\n"><meta property='og:url' content='https://fingertap.github.io/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/'><meta property='og:site_name' content='张晗的随笔'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='machine learning'><meta property='article:published_time' content='2025-03-18T22:17:03+08:00'><meta property='article:modified_time' content='2025-03-18T22:17:03+08:00'><meta property='og:image' content='https://fingertap.github.io/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/cover.png'><meta name=twitter:title content="从拒绝采样到投机推理"><meta name=twitter:description content="这两天看到ICLR 2025的一篇Oral做投机采样和级联模型结合，突然感觉以前拒绝采样的知识都很模糊了，于是有了这篇梳理拒绝采样的文章。\n采样问题 经典的采样问题是说，我希望从某个空间中采样出一些$x$，其采样出来的概率服从一个分布$\\pi(x)$。\n举例来说，如果这个空间是像素空间，分布$\\pi(x)$的概率密度聚集于猫狗照片，那么我们期望从中采样出来的$x$都是一些小猫小狗的照片；如果这个空间是句子空间，分布$\\pi(x)$的概率密度聚集于一些中文语料，那么我们期望从中采样出来的$x$都是一些中文的句子。\n对于一个简单的分布，我们可以用change of variable规则，将均匀分布转换成目标分布。然而，这种方法对于无法积分或者甚至没有解析表达的分布而言是不可行的。对于这样的分布，我们假设我们对于任意$x$，可以计算其概率密度$\\pi(x)$，希望能采样出一系列样本$\\left\\lbrace x_i\\right\\rbrace_{i=1}^N$，使得每个样本被采样到的概率$P\\left(X=x_i\\right)$等于其真实概率$\\pi\\left(x_i\\right)$。\n朴素的拒绝采样 朴素的拒绝采样的做法是给定一个提议分布 $q(x)$ ，将其乘上一个常数$k$以保证在任意 $x$ 处 $kq(x)\\geq\\pi(x)$ 。有了这个条件以后，我们按照这样的拒绝采样流程得到样本：\n从提议分布 $q(x)$ 中采样得到样本$x$， 以概率 $\\frac{\\pi(x)}{k \\cdot q(x)}$ 接受这个样本。 显然对于所有被接受的样本，其被采样的概率是正比与$\\pi(x)$的。然而，如下图所示，所有红色部分都会被拒绝，因此朴素的拒绝采样的样本效率可能会较低，一个更紧的提议分布上界带来的拒绝率越低。\n适应性拒绝采样 朴素的拒绝采样有可能连续出现样本被拒绝的情况。这在目标分布非常尖锐，提议分布无法很紧地包住它时常见（例如上图中2峰变为N峰，提议分布仍然使用高斯时）。适应性的拒绝采样可以有效提高采样效率，降低拒绝率。\n适应性采样保证了不会出现连续被拒绝的样本。其核心思想是将采样的概率质量区域划分为三部分：\n拒绝区域 $q(x)>\\pi(x)$ ，即下图的红色区域。 接受区域 $\\min(q(x), \\pi(x))$ ，即下图的绿色区域。 重采样区域 $\\max(\\pi(x) - q(x), 0)$ ，即下图的蓝色区域。 其中，对于属于重采样区域的样本$x$，其概率密度正比于 $\\max(\\pi(x) - q(x), 0)$ 。具体采样流程如下：\n从提议分布 $q(x)$ 中采样得到样本$x$， 以概率 $\\min\\left(\\frac{\\pi(x)}{q(x)}, 1\\right)$ 接受这个样本（即落在绿色区域即接受）。 若拒绝了此样本$x$，从蓝色区域采样一个样本出来。 适应性拒绝采样可以保证两次采样必然能获得至少一个接受样本 。然而，重采样过程和从原分布采样是类似的，在无法积分的情况下不可行，但是在大语言模型的生成分布是多项分布，因此投机推理中适应性采样恰好合用。\n"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://fingertap.github.io/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/cover.png'><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_ce70c8f8535541a2.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🇨🇳</span></figure><div class=site-meta><h1 class=site-name><a href=/>张晗的随笔</a></h1><h2 class=site-description>看风景 > 爬上山顶</h2></div></header><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/about-me/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>About Me</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#采样问题>采样问题</a></li><li><a href=#朴素的拒绝采样>朴素的拒绝采样</a></li><li><a href=#适应性拒绝采样>适应性拒绝采样</a></li><li><a href=#在线采样>在线采样</a></li><li><a href=#metroplis采样>Metroplis采样</a></li><li><a href=#投机推理>投机推理</a></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/><img src=/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/cover_hu_ed522213071172e1.png srcset="/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/cover_hu_ed522213071172e1.png 800w, /p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/cover_hu_ad738e45d0a62e78.png 1600w" width=800 height=800 loading=lazy alt="Featured image of post 从拒绝采样到投机推理"></a></div><div class=article-details><header class=article-category><a href=/categories/machine-learning/>Machine Learning</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/>从拒绝采样到投机推理</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Mar 18, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 2 分钟</time></div></footer></div></header><section class=article-content><p>这两天看到ICLR 2025的一篇Oral做投机采样和级联模型结合，突然感觉以前拒绝采样的知识都很模糊了，于是有了这篇梳理拒绝采样的文章。</p><h2 id=采样问题>采样问题</h2><p>经典的采样问题是说，我希望从某个空间中采样出一些$x$，其采样出来的概率服从一个分布$\pi(x)$。</p><p>举例来说，如果这个空间是像素空间，分布$\pi(x)$的概率密度聚集于猫狗照片，那么我们期望从中采样出来的$x$都是一些小猫小狗的照片；如果这个空间是句子空间，分布$\pi(x)$的概率密度聚集于一些中文语料，那么我们期望从中采样出来的$x$都是一些中文的句子。</p><p>对于一个简单的分布，我们可以用<a class=link href=https://online.stat.psu.edu/stat414/lesson/22/22.2 target=_blank rel=noopener>change of variable规则</a>，将均匀分布转换成目标分布。然而，这种方法对于无法积分或者甚至没有解析表达的分布而言是不可行的。对于这样的分布，我们假设我们对于任意$x$，可以计算其概率密度$\pi(x)$，希望能采样出一系列样本$\left\lbrace x_i\right\rbrace_{i=1}^N$，使得每个样本被采样到的概率$P\left(X=x_i\right)$等于其真实概率$\pi\left(x_i\right)$。</p><h2 id=朴素的拒绝采样>朴素的拒绝采样</h2><p>朴素的拒绝采样的做法是给定一个提议分布 $q(x)$ ，将其乘上一个常数$k$以保证在任意 $x$ 处 $kq(x)\geq\pi(x)$ 。有了这个条件以后，我们按照这样的拒绝采样流程得到样本：</p><ol><li>从提议分布 $q(x)$ 中采样得到样本$x$，</li><li>以概率 $\frac{\pi(x)}{k \cdot q(x)}$ 接受这个样本。</li></ol><p>显然对于所有被接受的样本，其被采样的概率是正比与$\pi(x)$的。然而，如下图所示，所有红色部分都会被拒绝，因此朴素的拒绝采样的样本效率可能会较低，一个更紧的提议分布上界带来的拒绝率越低。</p><p><img src=/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/naive_rej.png width=1000 height=500 srcset="/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/naive_rej_hu_fba22502dd4ee8db.png 480w, /p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/naive_rej_hu_95f05df02036855b.png 1024w" loading=lazy alt="Naive Rejection Sampling" class=gallery-image data-flex-grow=200 data-flex-basis=480px></p><h2 id=适应性拒绝采样>适应性拒绝采样</h2><p>朴素的拒绝采样有可能连续出现样本被拒绝的情况。这在目标分布非常尖锐，提议分布无法很紧地包住它时常见（例如上图中2峰变为N峰，提议分布仍然使用高斯时）。适应性的拒绝采样可以有效提高采样效率，降低拒绝率。</p><p>适应性采样保证了不会出现连续被拒绝的样本。其核心思想是将采样的概率质量区域划分为三部分：</p><ol><li>拒绝区域 $q(x)>\pi(x)$ ，即下图的红色区域。</li><li>接受区域 $\min(q(x), \pi(x))$ ，即下图的绿色区域。</li><li>重采样区域 $\max(\pi(x) - q(x), 0)$ ，即下图的蓝色区域。</li></ol><p><img src=/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/adaptive_rej.png width=1000 height=600 srcset="/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/adaptive_rej_hu_1d36b855f7ff9475.png 480w, /p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/adaptive_rej_hu_46163e22aef1a2fa.png 1024w" loading=lazy alt="Adaptive Rejection Sampling" class=gallery-image data-flex-grow=166 data-flex-basis=400px></p><p>其中，对于属于重采样区域的样本$x$，其概率密度正比于 $\max(\pi(x) - q(x), 0)$ 。具体采样流程如下：</p><ol><li>从提议分布 $q(x)$ 中采样得到样本$x$，</li><li>以概率 $\min\left(\frac{\pi(x)}{q(x)}, 1\right)$ 接受这个样本（即落在绿色区域即接受）。</li><li>若拒绝了此样本$x$，从蓝色区域采样一个样本出来。</li></ol><p>适应性拒绝采样可以保证两次采样必然能获得至少一个接受样本 。然而，重采样过程和从原分布采样是类似的，在无法积分的情况下不可行，但是在大语言模型的生成分布是多项分布，因此投机推理中适应性采样恰好合用。</p><details><summary>细节推导</summary><p>分情况讨论。</p><p>记第一次采样的样本为 $x$ ，若 $q(x) > \pi(x)$ ，且最终 $x$ 被接受，这时和经典拒绝采样等价。</p><p>若 $q(x) > \pi(x)$ 且最终 $x$ 被拒绝，这时会在 $S=\lbrace x | \pi(x) > q(x)\rbrace$区域采样，记此时采样的样本为 $x&rsquo;$ 。则样本被采样到的概率质量 $P(X=x&rsquo;) = \frac{\pi(x) - q(x)}{Resample Area}$ , 最关键的部分是需要知道上图中蓝色部分和红色部分的概率面积是相等的，都等于 $1-\text{Acceptance Area}$ 。因此重采样到 $x&rsquo;$ 的概率是 $\pi(x&rsquo;) - q(x&rsquo;)$。再加上一开始如果采样到 $S$ 时直接接受，概率为 $q(x&rsquo;)$，因此在 $S$ 区域的采样概率也为 $\pi(x)$ 。</p></details><h2 id=在线采样>在线采样</h2><p>在线采样是一种在数据流或实时数据环境中进行数据采样的方法。与传统的离线采样不同，在线采样需要在数据到达时即时进行决策，以确定是否将该数据点包含在样本中。这里我们主要考虑蓄水池采样（reservoir sampling），即数据点源源不断，可能永远不会停止的情形。在任意时刻，要求采样出来的 $K$ 个样本都是无偏的，采样概率由分布 $\pi(x)$ 决定。</p><p>假设我们要采样 $K$ 个样本，记采样的样本构成的集合为 $S_t$ ，样本为 $x_t$，维护一个历史的所有样本的权重和 $W_t$。在线采样通过以下的流程保证采样过程服从 $\pi(x)$ ：</p><ol><li>若 $|S_t| &lt; K$ ，$S_t = S_{t-1} \cup \lbrace x_t \rbrace$</li><li>若 $|S_t| \geq K$ , 累加权重 $W_t=W_{t-1}+\pi(x_t)$</li><li>以 $\frac{\pi(x)}{W_t}$ 的概率接受该样本并随机替换掉一个已采样的样本</li></ol><details><summary>简单证明</summary><p>假设在 $t-1$ 时刻是无偏采样，对任意一个样本 $x_i$ ，其采样的概率都是 $\frac{\pi(x_i)}{W_{t-1}}$ ，那么在 $t$ 时刻，旧元素的保留概率为</p>$$
P(x_i \in S_t) = P(x_i \in S_{t-1}) \cdot \left[ 1 - \frac{\pi(x_i)}{W_t}\cdot \frac{1}{K} \cdot K \right] = \frac{\pi(x_i)}{W_{t-1}} \cdot \frac{W_t - \pi(x_i)}{W_t} = \frac{\pi(x_i)}{W_t}
$$<p>等于新元素被保留的概率，因此 $t$ 时刻也是无偏的采样。</p></details><h2 id=metroplis采样>Metroplis采样</h2><p>Metroplis采样是著名的MCMC采样中使用的方法。其核心思想是用局部的提议分布代替全局的提议分布，从而避免全局提议分布带来的低采样率。其成立的条件是ergodicity和detailed balance。前者不用多说，后者其实本质是一个充分条件，描述的是稳态时任意一个采样值 $x$ 的流出概率密度（从 $x$ 转移到其他状态的概率）等于其流入的概率密度。</p><p>Metropolis采样的具体流程如下：</p><ol><li>给定当前状态 $x_t$，从提议分布 $q(x|x_t)$ 中采样得到候选状态 $x'$</li><li>以概率 $\min\left(1, \frac{\pi(x&rsquo;)q(x_t|x&rsquo;)}{\pi(x_t)q(x&rsquo;|x_t)}\right)$ 接受候选状态，即 $x_{t+1} = x&rsquo;$，否则保持当前状态 $x_{t+1} = x_t$</li></ol><p>其中，$\pi(x)$ 是目标分布，$q(x|x_t)$ 是提议分布。如果提议分布是对称的，即 $q(x|x_t) = q(x_t|x)$，那么接受概率可以简化为 $\min\left(1, \frac{\pi(x&rsquo;)}{\pi(x_t)}\right)$。</p><details><summary>Detailed Balance</summary><p>Metroplis采样基于局部的稳态（detailed balance），要求从任意一个状态流出的概率质量等于流入该状态的概率质量。记当前状态为 $x_t$ ，转移到 $x&rsquo;$ 的接收概率为 $\alpha(x&rsquo;|x_t) = \min\left(1, \frac{\pi(x&rsquo;)q(x_t|x&rsquo;)}{\pi(x_t)q(x&rsquo;|x_t)}\right)$ ，那么总有</p>$$
\pi(x_t)q(x'|x_t)\alpha(x'|x_t) = \pi(x')q(x_t|x')\alpha(x_t|x')
$$<p>原因是 $\alpha(x&rsquo;|x_t)$ 和 $\alpha(x_t|x&rsquo;)$ 总是一个为1，另一个不为1。在这种情况下，假设在 $t$ 时刻已经达到了目标分布，即 $P(X_t=x)\pi(x)$ ，那么在 $t+1$ 时刻我们希望仍然保证是目标分布。</p><p>由于对于任意状态$x&rsquo;$，其概率质量来自两部分：</p><ul><li>从其他状态$x_t$转移过来的概率</li><li>保持在原状态的概率</li></ul><p>因此有</p>$$
\begin{aligned}
P(X_{t+1}=x') &= \sum_{x_t}\pi(x_t)\cdot q(x'|x_t) \cdot \alpha(x'|x_t) + \pi(x')\cdot \left(\sum_{x_t}q(x_t|x')\cdot [1 - \alpha(x_t|x')]\right) \\
&= \sum_{x_t}\pi(x')q(x_t|x')\alpha(x_t|x') + \pi(x')\sum_{x_t}q(x_t|x') - \pi(x')\sum_{x_t}q(x_t|x')\alpha(x_t|x') \\
&= \pi(x')
\end{aligned}
$$</details><h2 id=投机推理>投机推理</h2><p>投机推理 （speculative inference）和Metroplis采样几乎相同，其中提议分布为一个小的语言模型。对于第一个被拒绝的样本，投机采样使用适应性拒绝采样，原因是两个语言模型的输出分布都是已知的Categorical分布。只需要找出所有大模型比小模型高的logits，非负截断并做归一化以后直接采样即可。</p></section><footer class=article-footer><section class=article-tags><a href=/tags/machine-learning/>Machine Learning</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84kl%E6%95%A3%E5%BA%A6%E4%BC%B0%E8%AE%A1/><div class=article-image><img src=/p/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84kl%E6%95%A3%E5%BA%A6%E4%BC%B0%E8%AE%A1/cover.b4fff78720d50821465ba154fdc2df26_hu_3b4a1b04b09dd2a6.png width=250 height=150 loading=lazy alt="Featured image of post 一种新的KL散度估计" data-hash="md5-tP/3hyDVCCFGW6FU/cLfJg=="></div><div class=article-details><h2 class=article-title>一种新的KL散度估计</h2></div></a></article><article class=has-image><a href=/p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%94%B6%E6%95%9B%E5%88%86%E6%9E%90/><div class=article-image><img src=/p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%94%B6%E6%95%9B%E5%88%86%E6%9E%90/cover.0f792aeaf735d1882c7842d7f7a09182_hu_934424ce9ce33e5a.png width=250 height=150 loading=lazy alt="Featured image of post 梯度下降收敛分析" data-hash="md5-D3kq6vc10YgseELX96CRgg=="></div><div class=article-details><h2 class=article-title>梯度下降收敛分析</h2></div></a></article><article class=has-image><a href=/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/><div class=article-image><img src=/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/cover.14e58351554cfa73826426d3e2e1aace_hu_a47d951a9fa767ee.png width=250 height=150 loading=lazy alt="Featured image of post 隐变量模型总结" data-hash="md5-FOWDUVVM+nOCZCbT4uGqzg=="></div><div class=article-details><h2 class=article-title>隐变量模型总结</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2025 张晗的随笔</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>
<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="è¿™ç¯‡é‡Œè®°å½•ä¸€ä¸‹æ¢¯åº¦ä¸‹é™åœ¨ä¸€èˆ¬æ¡ä»¶ä¸‹çš„æ”¶æ•›åˆ†æã€‚å…³é”®çš„æ€æƒ³æœ‰\nåˆ©ç”¨æ³°å‹’å…¬å¼+æ‹‰æ ¼æœ—æ—¥ä½™é¡¹å¯¹å‡½æ•°åšäºŒé˜¶å±•å¼€ã€‚ Smoothå’ŒConvexityåˆ†åˆ«å¯¹æ¢¯åº¦ã€æµ·å¡å¼•å…¥ä¸Šä¸‹ç•Œã€‚ æ”¶æ•›$\\Leftrightarrow f$æ˜¯Lipschitz smoothï¼ˆstochasticæƒ…å½¢ä¸‹ä¹Ÿéœ€è¦å‡è®¾æ¬¡æ¢¯åº¦æ–¹å·®æœ‰ç•Œï¼Œè¿™ç­‰äºæ˜¯è¯´smoothï¼Œç”šè‡³æ¯”smoothæ›´å¼ºå› ä¸ºsmoothnessç­‰ä»·äºæ¢¯åº¦å¹³æ–¹æœ‰ä¸Šç•Œï¼‰ã€‚ æ”¶æ•›é€Ÿåº¦å–å†³äº$|\\nabla f(x)|$çš„ä¸‹ç•Œï¼Œå³æœ‰å¤šconvexã€‚ æ³¨ï¼šç”¨$|x-x^\\star|^2$å’Œ$f(x)-f(x^\\star)$æ¥æ¨å¯¼ç»“æœæ˜¯ä¸€è‡´çš„ï¼Œå‰è€…ç”¨å®Œå…¨å¹³æ–¹å…¬å¼å±•å¼€ï¼Œåè€…ç”¨æ³°å‹’å±•å¼€ã€‚\nè¡¨æ ¼ç»“æœ å‡è®¾Lipschitzå¹³æ»‘å¸¸æ•°ä¸º$M$ï¼Œå¼ºå‡¸å¸¸æ•°ä¸º$m$ï¼Œåˆå§‹è·ç¦»æœ€ä¼˜å€¼è·ç¦»$|x_0-x^\\star|\\leq r$ï¼Œåˆå§‹å‡½æ•°å€¼å·®è·$f(x_0)-f(x^\\star)\\leq R$ï¼Œéšæœºæƒ…å½¢ä¸‹å‡è®¾$\\mathbb{E}[|\\tilde g_{\\theta}|\\theta|^2]\\leq B^2$ï¼Œæœ‰ä»¥ä¸‹ç»“æœï¼š\nMethods Non-smooth Smooth+Non-convex Smooth+Convex Smooth+Strong Convexity Gradient Descent May Divergent Converge to local optima $O(\\frac{Mr^2}{K})$ $O\\left(\\left(1-\\frac{m}{M}\\right)^KR\\right)$ Stochastic Gradient Descent May Divergent Almost surely converge to Critical points $O(\\frac{Br}{\\sqrt{K}})$ $O(\\frac{B^2}{mK})$ å¯¹äºä¸€èˆ¬éå‡¸éå…‰æ»‘é—®é¢˜çš„æ”¶æ•›é€Ÿåº¦çš„ç•Œæˆ‘ä»¬æ²¡æœ‰å¥½çš„ç»“æœï¼Œå› ä¸ºè¿™è‡³å°‘æ˜¯NPéš¾é—®é¢˜ã€‚\nåŸºç¡€ è€ƒè™‘å¯å¯¼å‡½æ•°$f:\\mathbb{R}^d\\rightarrow\\mathbb{R}$ï¼Œåœ¨ä»»ä¸€ç‚¹å¤„å±•å¼€æœ‰ï¼š\n$$ f(x) = f(y) + (x-y)^T\\nabla f(y) + (x-y)^T\\nabla^2f(c)(x-y), \\tag{1} $$å…¶ä¸­$c$æ˜¯$x$å’Œ$y$çº¿æ®µä¸Šä¸€ç‚¹ã€‚\nConvexityã€Strong Convexityã€Lipschitz Smooth æˆ‘ä»¬è¯´ä»–æ˜¯å‡¸å‡½æ•°ï¼Œæ„å‘³ç€$\\forall c\\in\\mathbf{dom}f, \\nabla^2f(c)\\succeq0$ï¼Œå³$\\forall x, y\\in \\mathbf{dom}f$\n$$ f(x) \\geq f(y) + (x-y)^T\\nabla f(y). $$Lipschitz smoothå’ŒStrong convexityç±»ä¼¼ï¼Œæ˜¯å¯¹$\\nabla^2f(c)$å¼•å…¥äº†ä¸Šä¸‹ç•Œã€‚å‡è®¾$f(x)$æ˜¯$M$-Lipschitz smoothï¼Œä»¥åŠ$m$-strongly convexï¼Œæœ‰$\\forall c\\in\\mathbf{dom}f$\n"><title>æ¢¯åº¦ä¸‹é™æ”¶æ•›åˆ†æ</title>
<link rel=canonical href=https://fingertap.github.io/p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%94%B6%E6%95%9B%E5%88%86%E6%9E%90/><link rel=stylesheet href=/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="æ¢¯åº¦ä¸‹é™æ”¶æ•›åˆ†æ"><meta property='og:description' content="è¿™ç¯‡é‡Œè®°å½•ä¸€ä¸‹æ¢¯åº¦ä¸‹é™åœ¨ä¸€èˆ¬æ¡ä»¶ä¸‹çš„æ”¶æ•›åˆ†æã€‚å…³é”®çš„æ€æƒ³æœ‰\nåˆ©ç”¨æ³°å‹’å…¬å¼+æ‹‰æ ¼æœ—æ—¥ä½™é¡¹å¯¹å‡½æ•°åšäºŒé˜¶å±•å¼€ã€‚ Smoothå’ŒConvexityåˆ†åˆ«å¯¹æ¢¯åº¦ã€æµ·å¡å¼•å…¥ä¸Šä¸‹ç•Œã€‚ æ”¶æ•›$\\Leftrightarrow f$æ˜¯Lipschitz smoothï¼ˆstochasticæƒ…å½¢ä¸‹ä¹Ÿéœ€è¦å‡è®¾æ¬¡æ¢¯åº¦æ–¹å·®æœ‰ç•Œï¼Œè¿™ç­‰äºæ˜¯è¯´smoothï¼Œç”šè‡³æ¯”smoothæ›´å¼ºå› ä¸ºsmoothnessç­‰ä»·äºæ¢¯åº¦å¹³æ–¹æœ‰ä¸Šç•Œï¼‰ã€‚ æ”¶æ•›é€Ÿåº¦å–å†³äº$|\\nabla f(x)|$çš„ä¸‹ç•Œï¼Œå³æœ‰å¤šconvexã€‚ æ³¨ï¼šç”¨$|x-x^\\star|^2$å’Œ$f(x)-f(x^\\star)$æ¥æ¨å¯¼ç»“æœæ˜¯ä¸€è‡´çš„ï¼Œå‰è€…ç”¨å®Œå…¨å¹³æ–¹å…¬å¼å±•å¼€ï¼Œåè€…ç”¨æ³°å‹’å±•å¼€ã€‚\nè¡¨æ ¼ç»“æœ å‡è®¾Lipschitzå¹³æ»‘å¸¸æ•°ä¸º$M$ï¼Œå¼ºå‡¸å¸¸æ•°ä¸º$m$ï¼Œåˆå§‹è·ç¦»æœ€ä¼˜å€¼è·ç¦»$|x_0-x^\\star|\\leq r$ï¼Œåˆå§‹å‡½æ•°å€¼å·®è·$f(x_0)-f(x^\\star)\\leq R$ï¼Œéšæœºæƒ…å½¢ä¸‹å‡è®¾$\\mathbb{E}[|\\tilde g_{\\theta}|\\theta|^2]\\leq B^2$ï¼Œæœ‰ä»¥ä¸‹ç»“æœï¼š\nMethods Non-smooth Smooth+Non-convex Smooth+Convex Smooth+Strong Convexity Gradient Descent May Divergent Converge to local optima $O(\\frac{Mr^2}{K})$ $O\\left(\\left(1-\\frac{m}{M}\\right)^KR\\right)$ Stochastic Gradient Descent May Divergent Almost surely converge to Critical points $O(\\frac{Br}{\\sqrt{K}})$ $O(\\frac{B^2}{mK})$ å¯¹äºä¸€èˆ¬éå‡¸éå…‰æ»‘é—®é¢˜çš„æ”¶æ•›é€Ÿåº¦çš„ç•Œæˆ‘ä»¬æ²¡æœ‰å¥½çš„ç»“æœï¼Œå› ä¸ºè¿™è‡³å°‘æ˜¯NPéš¾é—®é¢˜ã€‚\nåŸºç¡€ è€ƒè™‘å¯å¯¼å‡½æ•°$f:\\mathbb{R}^d\\rightarrow\\mathbb{R}$ï¼Œåœ¨ä»»ä¸€ç‚¹å¤„å±•å¼€æœ‰ï¼š\n$$ f(x) = f(y) + (x-y)^T\\nabla f(y) + (x-y)^T\\nabla^2f(c)(x-y), \\tag{1} $$å…¶ä¸­$c$æ˜¯$x$å’Œ$y$çº¿æ®µä¸Šä¸€ç‚¹ã€‚\nConvexityã€Strong Convexityã€Lipschitz Smooth æˆ‘ä»¬è¯´ä»–æ˜¯å‡¸å‡½æ•°ï¼Œæ„å‘³ç€$\\forall c\\in\\mathbf{dom}f, \\nabla^2f(c)\\succeq0$ï¼Œå³$\\forall x, y\\in \\mathbf{dom}f$\n$$ f(x) \\geq f(y) + (x-y)^T\\nabla f(y). $$Lipschitz smoothå’ŒStrong convexityç±»ä¼¼ï¼Œæ˜¯å¯¹$\\nabla^2f(c)$å¼•å…¥äº†ä¸Šä¸‹ç•Œã€‚å‡è®¾$f(x)$æ˜¯$M$-Lipschitz smoothï¼Œä»¥åŠ$m$-strongly convexï¼Œæœ‰$\\forall c\\in\\mathbf{dom}f$\n"><meta property='og:url' content='https://fingertap.github.io/p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%94%B6%E6%95%9B%E5%88%86%E6%9E%90/'><meta property='og:site_name' content='å¼ æ™—çš„éšç¬”'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='Machine Learning'><meta property='article:tag' content='Math'><meta property='article:published_time' content='2019-07-28T23:34:55+08:00'><meta property='article:modified_time' content='2019-07-28T23:34:55+08:00'><meta property='og:image' content='https://fingertap.github.io/p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%94%B6%E6%95%9B%E5%88%86%E6%9E%90/cover.png'><meta name=twitter:title content="æ¢¯åº¦ä¸‹é™æ”¶æ•›åˆ†æ"><meta name=twitter:description content="è¿™ç¯‡é‡Œè®°å½•ä¸€ä¸‹æ¢¯åº¦ä¸‹é™åœ¨ä¸€èˆ¬æ¡ä»¶ä¸‹çš„æ”¶æ•›åˆ†æã€‚å…³é”®çš„æ€æƒ³æœ‰\nåˆ©ç”¨æ³°å‹’å…¬å¼+æ‹‰æ ¼æœ—æ—¥ä½™é¡¹å¯¹å‡½æ•°åšäºŒé˜¶å±•å¼€ã€‚ Smoothå’ŒConvexityåˆ†åˆ«å¯¹æ¢¯åº¦ã€æµ·å¡å¼•å…¥ä¸Šä¸‹ç•Œã€‚ æ”¶æ•›$\\Leftrightarrow f$æ˜¯Lipschitz smoothï¼ˆstochasticæƒ…å½¢ä¸‹ä¹Ÿéœ€è¦å‡è®¾æ¬¡æ¢¯åº¦æ–¹å·®æœ‰ç•Œï¼Œè¿™ç­‰äºæ˜¯è¯´smoothï¼Œç”šè‡³æ¯”smoothæ›´å¼ºå› ä¸ºsmoothnessç­‰ä»·äºæ¢¯åº¦å¹³æ–¹æœ‰ä¸Šç•Œï¼‰ã€‚ æ”¶æ•›é€Ÿåº¦å–å†³äº$|\\nabla f(x)|$çš„ä¸‹ç•Œï¼Œå³æœ‰å¤šconvexã€‚ æ³¨ï¼šç”¨$|x-x^\\star|^2$å’Œ$f(x)-f(x^\\star)$æ¥æ¨å¯¼ç»“æœæ˜¯ä¸€è‡´çš„ï¼Œå‰è€…ç”¨å®Œå…¨å¹³æ–¹å…¬å¼å±•å¼€ï¼Œåè€…ç”¨æ³°å‹’å±•å¼€ã€‚\nè¡¨æ ¼ç»“æœ å‡è®¾Lipschitzå¹³æ»‘å¸¸æ•°ä¸º$M$ï¼Œå¼ºå‡¸å¸¸æ•°ä¸º$m$ï¼Œåˆå§‹è·ç¦»æœ€ä¼˜å€¼è·ç¦»$|x_0-x^\\star|\\leq r$ï¼Œåˆå§‹å‡½æ•°å€¼å·®è·$f(x_0)-f(x^\\star)\\leq R$ï¼Œéšæœºæƒ…å½¢ä¸‹å‡è®¾$\\mathbb{E}[|\\tilde g_{\\theta}|\\theta|^2]\\leq B^2$ï¼Œæœ‰ä»¥ä¸‹ç»“æœï¼š\nMethods Non-smooth Smooth+Non-convex Smooth+Convex Smooth+Strong Convexity Gradient Descent May Divergent Converge to local optima $O(\\frac{Mr^2}{K})$ $O\\left(\\left(1-\\frac{m}{M}\\right)^KR\\right)$ Stochastic Gradient Descent May Divergent Almost surely converge to Critical points $O(\\frac{Br}{\\sqrt{K}})$ $O(\\frac{B^2}{mK})$ å¯¹äºä¸€èˆ¬éå‡¸éå…‰æ»‘é—®é¢˜çš„æ”¶æ•›é€Ÿåº¦çš„ç•Œæˆ‘ä»¬æ²¡æœ‰å¥½çš„ç»“æœï¼Œå› ä¸ºè¿™è‡³å°‘æ˜¯NPéš¾é—®é¢˜ã€‚\nåŸºç¡€ è€ƒè™‘å¯å¯¼å‡½æ•°$f:\\mathbb{R}^d\\rightarrow\\mathbb{R}$ï¼Œåœ¨ä»»ä¸€ç‚¹å¤„å±•å¼€æœ‰ï¼š\n$$ f(x) = f(y) + (x-y)^T\\nabla f(y) + (x-y)^T\\nabla^2f(c)(x-y), \\tag{1} $$å…¶ä¸­$c$æ˜¯$x$å’Œ$y$çº¿æ®µä¸Šä¸€ç‚¹ã€‚\nConvexityã€Strong Convexityã€Lipschitz Smooth æˆ‘ä»¬è¯´ä»–æ˜¯å‡¸å‡½æ•°ï¼Œæ„å‘³ç€$\\forall c\\in\\mathbf{dom}f, \\nabla^2f(c)\\succeq0$ï¼Œå³$\\forall x, y\\in \\mathbf{dom}f$\n$$ f(x) \\geq f(y) + (x-y)^T\\nabla f(y). $$Lipschitz smoothå’ŒStrong convexityç±»ä¼¼ï¼Œæ˜¯å¯¹$\\nabla^2f(c)$å¼•å…¥äº†ä¸Šä¸‹ç•Œã€‚å‡è®¾$f(x)$æ˜¯$M$-Lipschitz smoothï¼Œä»¥åŠ$m$-strongly convexï¼Œæœ‰$\\forall c\\in\\mathbf{dom}f$\n"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://fingertap.github.io/p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%94%B6%E6%95%9B%E5%88%86%E6%9E%90/cover.png'><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=åˆ‡æ¢èœå•>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_ce70c8f8535541a2.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>ğŸ‡¨ğŸ‡³</span></figure><div class=site-meta><h1 class=site-name><a href=/>å¼ æ™—çš„éšç¬”</a></h1><h2 class=site-description>çœ‹é£æ™¯ > çˆ¬ä¸Šå±±é¡¶</h2></div></header><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/about-me/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>About Me</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>æš—è‰²æ¨¡å¼</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">ç›®å½•</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#è¡¨æ ¼ç»“æœ>è¡¨æ ¼ç»“æœ</a></li><li><a href=#åŸºç¡€>åŸºç¡€</a><ol><li><a href=#convexitystrong-convexitylipschitz-smooth>Convexityã€Strong Convexityã€Lipschitz Smooth</a></li><li><a href=#machine-learning-lossgradient-descentstochastic-gradient-descent>Machine Learning Lossã€Gradient Descentã€Stochastic Gradient Descent</a></li><li><a href=#relationship-between-gradient-and-stochastic-gradientsubgradient>Relationship between Gradient and Stochastic Gradientã€Subgradient</a></li></ol></li><li><a href=#æ”¶æ•›æ€§åˆ†æ>æ”¶æ•›æ€§åˆ†æ</a><ol><li><a href=#gradient-descent>Gradient Descent</a><ol><li><a href=#convexæƒ…å½¢>Convexæƒ…å½¢</a></li><li><a href=#m-strongly-convexæƒ…å½¢>$m$-strongly convexæƒ…å½¢</a></li></ol></li><li><a href=#stochastic-gradient-descent>Stochastic Gradient Descent</a><ol><li><a href=#convexæƒ…å½¢-1>Convexæƒ…å½¢</a></li><li><a href=#strong-convexæƒ…å½¢>Strong Convexæƒ…å½¢</a></li></ol></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%94%B6%E6%95%9B%E5%88%86%E6%9E%90/><img src=/p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%94%B6%E6%95%9B%E5%88%86%E6%9E%90/cover_hu_969f1c0c6e2718b5.png srcset="/p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%94%B6%E6%95%9B%E5%88%86%E6%9E%90/cover_hu_969f1c0c6e2718b5.png 800w, /p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%94%B6%E6%95%9B%E5%88%86%E6%9E%90/cover_hu_e42ad02c82476eb8.png 1600w" width=800 height=800 loading=lazy alt="Featured image of post æ¢¯åº¦ä¸‹é™æ”¶æ•›åˆ†æ"></a></div><div class=article-details><header class=article-category><a href=/categories/machine-learning/>Machine Learning</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%94%B6%E6%95%9B%E5%88%86%E6%9E%90/>æ¢¯åº¦ä¸‹é™æ”¶æ•›åˆ†æ</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Jul 28, 2019</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>é˜…è¯»æ—¶é•¿: 3 åˆ†é’Ÿ</time></div></footer></div></header><section class=article-content><p>è¿™ç¯‡é‡Œè®°å½•ä¸€ä¸‹æ¢¯åº¦ä¸‹é™åœ¨ä¸€èˆ¬æ¡ä»¶ä¸‹çš„æ”¶æ•›åˆ†æã€‚å…³é”®çš„æ€æƒ³æœ‰</p><ol><li>åˆ©ç”¨æ³°å‹’å…¬å¼+æ‹‰æ ¼æœ—æ—¥ä½™é¡¹å¯¹å‡½æ•°åšäºŒé˜¶å±•å¼€ã€‚</li><li>Smoothå’ŒConvexityåˆ†åˆ«å¯¹æ¢¯åº¦ã€æµ·å¡å¼•å…¥ä¸Šä¸‹ç•Œã€‚</li><li>æ”¶æ•›$\Leftrightarrow f$æ˜¯Lipschitz smoothï¼ˆstochasticæƒ…å½¢ä¸‹ä¹Ÿéœ€è¦å‡è®¾æ¬¡æ¢¯åº¦æ–¹å·®æœ‰ç•Œï¼Œè¿™ç­‰äºæ˜¯è¯´smoothï¼Œç”šè‡³æ¯”smoothæ›´å¼ºå› ä¸ºsmoothnessç­‰ä»·äºæ¢¯åº¦å¹³æ–¹æœ‰ä¸Šç•Œï¼‰ã€‚</li><li>æ”¶æ•›é€Ÿåº¦å–å†³äº$|\nabla f(x)|$çš„ä¸‹ç•Œï¼Œå³æœ‰å¤šconvexã€‚</li></ol><p>æ³¨ï¼šç”¨$|x-x^\star|^2$å’Œ$f(x)-f(x^\star)$æ¥æ¨å¯¼ç»“æœæ˜¯ä¸€è‡´çš„ï¼Œå‰è€…ç”¨å®Œå…¨å¹³æ–¹å…¬å¼å±•å¼€ï¼Œåè€…ç”¨æ³°å‹’å±•å¼€ã€‚</p><hr><h2 id=è¡¨æ ¼ç»“æœ>è¡¨æ ¼ç»“æœ</h2><p>å‡è®¾Lipschitzå¹³æ»‘å¸¸æ•°ä¸º$M$ï¼Œå¼ºå‡¸å¸¸æ•°ä¸º$m$ï¼Œåˆå§‹è·ç¦»æœ€ä¼˜å€¼è·ç¦»$|x_0-x^\star|\leq r$ï¼Œåˆå§‹å‡½æ•°å€¼å·®è·$f(x_0)-f(x^\star)\leq R$ï¼Œéšæœºæƒ…å½¢ä¸‹å‡è®¾$\mathbb{E}[|\tilde g_{\theta}|\theta|^2]\leq B^2$ï¼Œæœ‰ä»¥ä¸‹ç»“æœï¼š</p><div class=table-wrapper><table><thead><tr><th style=text-align:center>Methods</th><th style=text-align:center>Non-smooth</th><th style=text-align:center>Smooth+Non-convex</th><th style=text-align:center>Smooth+Convex</th><th style=text-align:center>Smooth+Strong Convexity</th></tr></thead><tbody><tr><td style=text-align:center>Gradient Descent</td><td style=text-align:center>May Divergent</td><td style=text-align:center>Converge to local optima</td><td style=text-align:center>$O(\frac{Mr^2}{K})$</td><td style=text-align:center>$O\left(\left(1-\frac{m}{M}\right)^KR\right)$</td></tr><tr><td style=text-align:center>Stochastic Gradient Descent</td><td style=text-align:center>May Divergent</td><td style=text-align:center>Almost surely converge to Critical points</td><td style=text-align:center>$O(\frac{Br}{\sqrt{K}})$</td><td style=text-align:center>$O(\frac{B^2}{mK})$</td></tr></tbody></table></div><p>å¯¹äºä¸€èˆ¬éå‡¸éå…‰æ»‘é—®é¢˜çš„æ”¶æ•›é€Ÿåº¦çš„ç•Œæˆ‘ä»¬æ²¡æœ‰å¥½çš„ç»“æœï¼Œå› ä¸ºè¿™è‡³å°‘æ˜¯NPéš¾é—®é¢˜ã€‚</p><hr><h2 id=åŸºç¡€>åŸºç¡€</h2><p>è€ƒè™‘å¯å¯¼å‡½æ•°$f:\mathbb{R}^d\rightarrow\mathbb{R}$ï¼Œåœ¨ä»»ä¸€ç‚¹å¤„å±•å¼€æœ‰ï¼š</p>$$
f(x) = f(y) + (x-y)^T\nabla f(y) + (x-y)^T\nabla^2f(c)(x-y),
\tag{1}
$$<p>å…¶ä¸­$c$æ˜¯$x$å’Œ$y$çº¿æ®µä¸Šä¸€ç‚¹ã€‚</p><h3 id=convexitystrong-convexitylipschitz-smooth>Convexityã€Strong Convexityã€Lipschitz Smooth</h3><p>æˆ‘ä»¬è¯´ä»–æ˜¯<strong>å‡¸å‡½æ•°</strong>ï¼Œæ„å‘³ç€$\forall c\in\mathbf{dom}f, \nabla^2f(c)\succeq0$ï¼Œå³$\forall x, y\in \mathbf{dom}f$</p>$$
f(x) \geq f(y) + (x-y)^T\nabla f(y).
$$<p>Lipschitz smoothå’ŒStrong convexityç±»ä¼¼ï¼Œæ˜¯å¯¹$\nabla^2f(c)$å¼•å…¥äº†ä¸Šä¸‹ç•Œã€‚å‡è®¾$f(x)$æ˜¯$M$-Lipschitz smoothï¼Œä»¥åŠ$m$-strongly convexï¼Œæœ‰$\forall c\in\mathbf{dom}f$</p>$$
mI\preceq \nabla^2f(c)\preceq MI,
$$<p>å…¶ä¸­$I$æ˜¯å•ä½çŸ©é˜µã€‚æ³¨æ„è¿™æ ·ä¸€æ¥Convexå¯ä»¥çœ‹åšæ˜¯0-strongly convexã€‚Lipschitz smoothç›´è§‰ç†è§£å°±æ˜¯æ²¡æœ‰æŠ˜ç‚¹ï¼ˆä¾‹å¦‚$|x|$åœ¨$x=0$å¤„ï¼‰ï¼ŒStrong convexityç›´è§‰ç†è§£å°±æ˜¯æ²¡æœ‰ç›†åœ°ï¼ˆä¸€ç‰‡åŒºåŸŸçš„å‡½æ•°å€¼ç›¸ç­‰ï¼‰ã€‚å¦‚æœæˆ‘ä»¬è€ƒè™‘æœ€ä¼˜å€¼$x^\star$ï¼Œå¯¹äºå¼ºå‡¸å’Œsmoothæˆ‘ä»¬åˆ†åˆ«æœ‰</p>$$
2m\left\{f(x)-f(y)\right\}\leq\left\|\nabla f(x)\right\|^2\leq 2m\left\{f(x)-f(y)\right\}
$$<p>ï¼ˆä»£å…¥å¼(1)ï¼Œå³è¾¹å¯¹$y$æ±‚æå€¼ï¼‰</p><h3 id=machine-learning-lossgradient-descentstochastic-gradient-descent>Machine Learning Lossã€Gradient Descentã€Stochastic Gradient Descent</h3><p>å¯¹äºä¸€æ—æœ‰ç›‘ç£ç»Ÿè®¡å­¦ä¹ æ¨¡å‹$M_\theta$ï¼ˆæ¨¡å‹çš„å‚æ•°ä¸º$\theta\in\Theta$ï¼‰ï¼Œè®¾è¾“å…¥æ ·æœ¬-æ ‡ç­¾å¯¹$(x, y)\in\mathcal{D}$æ»¡è¶³$x\in\mathcal{X}, y\in\mathcal{Y}$ï¼Œæ¨¡å‹çš„å†³ç­–å‡½æ•°ï¼ˆæ³›å‡½ï¼‰ä¸º$f_\theta:\mathcal{X}\rightarrow\mathcal{Y}$ä¸ºè¿ç»­æ˜ å°„ã€‚ç»™å®šè¿ç»­çš„æŸå¤±å‡½æ•°$l:\mathcal{Y}\times\mathcal{Y}\rightarrow\mathbb{R}$ï¼Œä»¥åŠå®šä¹‰åœ¨$\mathcal{D}$ä¸Šçš„æ¦‚ç‡åº¦é‡$P$ï¼ˆå¯†åº¦å‡½æ•°ä¸ºpï¼‰ï¼Œä¸€ä¸ªæ¨¡å‹çš„å¥½åç”±æœŸæœ›æŸå¤±ç»™å‡ºï¼š</p>$$
L(M_\theta)\triangleq \mathbb{E}_{(x, y)\in\mathcal{D}}[l(f_\theta(x), y)]
$$<p>å¦‚æœæˆ‘ä»¬æ‹¿ä¸åˆ°è¾“å…¥ç©ºé—´$\mathcal{D}$ï¼ˆéœ€è¦æŒæ¡æ‰€æœ‰å¯èƒ½çš„æ•°æ®ç”Ÿæˆçš„æ–¹å¼ï¼Œä½†æ˜¯æˆ‘ä»¬å¦‚æœæœ‰è¿™ä¸ªç”Ÿæˆæ–¹å¼è¿˜è®­ç»ƒä»€ä¹ˆæ¨¡å‹å‘¢ï¼Ÿç›´æ¥æŸ¥è¡¨ä¸å¥½å—ï¼Ÿï¼‰å’Œæ¦‚ç‡åº¦é‡$P$ï¼Œåˆ™è¿™ä¸ªæœŸæœ›åªèƒ½ç”±æˆ‘ä»¬å·²æœ‰çš„æ•°æ®é›†$D\subset\mathcal{D}$æ¥è¿‘ä¼¼ï¼Œæ­¤æ—¶åœ¨$D$ä¸Šçš„æŸå¤±å«åšç»éªŒæŸå¤±ï¼š</p>$$
\hat{L}(M_\theta)\triangleq \frac{1}{|D|}\sum_{(x, y)\in D}l(f_\theta(x), y),
$$<p>è¿™é‡Œå‡è®¾äº†æ¯ä¸ªæ ·æœ¬éƒ½æ˜¯æœä»$P$ï¼Œä»$\mathcal{D}$ä¸­ç‹¬ç«‹æŠ½æ ·å‡ºæ¥çš„ã€‚åˆ™æ¢¯åº¦ä¸‹é™\(GD\)çš„æ›´æ–°ç­–ç•¥ï¼š</p>$$
\begin{align}
\theta_{k+1} &= \theta_k - \alpha \nabla l (\theta_k)\\
&=\theta_k - \alpha\cdot\frac{1}{D}\sum_{(x, y)\in D}\frac{\partial l(f_{\theta_k}(x), y)}{\partial \theta_k}.
\end{align}
$$<p>å½“$|D|$å¾ˆå¤§æ—¶è®¡ç®—$\nabla l(\theta_k)$çš„å¼€æ”¯è¾ƒå¤§ï¼Œéšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰å¯¹$D$è¿›è¡Œé‡‡æ ·ï¼Œç„¶åç”¨å¸¦æœ‰éšæœºæ€§çš„æ¢¯åº¦ä»£æ›¿æ¢¯åº¦ä¸‹é™ä¸­çš„$\nabla l(\theta_k)$ã€‚è®°é‡‡æ ·å¾—åˆ°çš„mini-batchä¸º$D_k\subset D$ï¼Œéšæœºæ¢¯åº¦å®šä¹‰ä¸º</p>$$
\nabla l_{D_k}(\theta_k) = \frac{1}{|D_k|}\sum_{(x, y)\in D_k}\frac{\partial l(f_{\theta_k}(x), y)}{\partial \theta_k}.
$$<p>ç”±äºä»»æ„ä¸€ä¸ªæ ·æœ¬$(x, y)$çš„æŸå¤±çš„æœŸæœ›éƒ½æ˜¯$L(M_\theta)$ï¼Œå¯ä»¥å¾ˆç®€å•åœ°è¯æ˜éšæœºæ¢¯åº¦å’Œç»éªŒæ¢¯åº¦çš„æœŸæœ›éƒ½æ˜¯æœŸæœ›æŸå¤±åœ¨$\theta$å¤„çš„æ¢¯åº¦ã€‚</p><p>æœ‰æ—¶å€™éšæœºæ¢¯åº¦ä¸‹é™çš„éšæœºæ€§å¹¶ä¸åªæ˜¯æ¥è‡ªäºå¯¹æ•°æ®çš„é‡‡æ ·ï¼ˆæ¯”å¦‚ä¸ºäº†ä½¿ç›®æ ‡å˜å¹³æ»‘ï¼Œå¯¹æ•°æ®åŠ å…¥éšæœºç™½å™ªå£°ï¼‰ï¼Œæ­¤æ—¶æœ‰å¯èƒ½ä½¿å¾—éšæœºæ¢¯åº¦å¹¶ä¸è½åœ¨å¯è¡ŒåŒºåŸŸå†…ï¼ˆæ¯”å¦‚$\theta_k=[0.1, 0.9]$ï¼Œè€Œæ¢¯åº¦ä¸º$-0.2, 1.1$ï¼Œè€Œæˆ‘ä»¬å¸Œæœ›$|\theta|<em>\infty\leq 1$ï¼‰ï¼Œè¿™æ—¶éœ€è¦åšä¸€æ­¥æ­£äº¤æŠ•å½±æ“ä½œï¼Œå°†æ›´æ–°åçš„$\theta</em>{k+1}$æŠ•å½±åˆ°å¯è¡ŒåŒºåŸŸ$\Theta$å†…ï¼Œæ–¹å¼æ˜¯ç”¨æœ€å°äºŒä¹˜æ³•åœ¨$\Theta$æ‰¾ä¸€ä¸ªè·ç¦»$\theta_{k+1}$æœ€è¿‘çš„ç‚¹$\tilde\theta_{k+1}$ï¼Œå®ƒæ»¡è¶³$\forall \theta\in \Theta, |\theta-\theta_{k+1}|\geq|\theta-\tilde\theta_{k+1}|$ï¼Œå³æŠ•å½±åè·ç¦»ä¼šç¼©å°ã€‚</p><h3 id=relationship-between-gradient-and-stochastic-gradientsubgradient>Relationship between Gradient and Stochastic Gradientã€Subgradient</h3><p>$f$åœ¨$x$å¤„çš„æ¬¡æ¢¯åº¦ï¼ˆSubgradientï¼‰$g_x\in\mathbb{R}^d$æ˜¯æ‰€æœ‰æ»¡è¶³ä¸€é˜¶æ¡ä»¶çš„å‘é‡ï¼š$\forall x, y\in \mathbb{R}^d,$</p>$$
f(y)\geq f(x) + g_x^T(y-x),
$$<p>æ‰€æœ‰æ¬¡æ¢¯åº¦çš„é›†åˆå«åšSubdifferentialï¼Œè®°ä½œ$\partial f(x)$ã€‚å½“$f$åœ¨$x$å¤„å¯å¯¼æ—¶ï¼Œ$\partial f(x) = {\nabla f(x)}$ã€‚ä¹Ÿå³ï¼Œå¦‚æœå‡½æ•°æ˜¯å…‰æ»‘çš„ï¼Œå°±ä¸ç”¨è€ƒè™‘æ¬¡æ¢¯åº¦ï¼Œå¯¹äºéå…‰æ»‘çš„é—®é¢˜ä¸€èˆ¬ä¼šç”¨æ¬¡æ¢¯åº¦ä¸‹é™æ¥åˆ†ææ”¶æ•›æ€§ç­‰ã€‚</p><p>æˆ‘ä»¬ç§°ä¸€ä¸ªå‘é‡$\tilde g_x$ä¸º$f$åœ¨$x$å¤„çš„å¸¦å™ªæ— åæ¬¡æ¢¯åº¦ï¼ˆNoisy Unbiased Subgradientï¼‰è‹¥$\mathbb{E}[\tilde g_x]=g_x\in\partial f(x)$ã€‚<strong>åˆ™éšæœºæ¢¯åº¦ä¸‹é™å¯ä»¥çœ‹åšåœ¨æ¢¯åº¦</strong>$\nabla l(\theta_k)$<strong>ä¸­å¼•å…¥ä¸€ä¸ªé›¶å‡å€¼çš„åŠ æ€§å™ªå£°ï¼Œè€Œè¿™ä¸ªå™ªå£°ä¸ºæ­¤æ¬¡mini-batchçš„æ³›å‡½ï¼Œè®°ä½œ</strong>$v(D_k)$ã€‚</p><hr><h2 id=æ”¶æ•›æ€§åˆ†æ>æ”¶æ•›æ€§åˆ†æ</h2><h3 id=gradient-descent>Gradient Descent</h3><p><strong>ç»“è®º</strong>ï¼š<em>æ¢¯åº¦ä¸‹é™åœ¨æ— Smoothå‡è®¾æ—¶å¯èƒ½ä¸æ”¶æ•›ï¼Œæœ‰M-smoothå‡è®¾æ—¶æ”¶æ•›ã€‚è¾¾åˆ°ç²¾åº¦</em>$\epsilon>0$<em>ï¼Œå‡¸æ—¶æ”¶æ•›é€Ÿåº¦ä¸º</em>$o(\frac{MR^2}{\epsilon})$<em>ï¼Œå¼ºå‡¸æ—¶æ”¶æ•›é€Ÿåº¦ä¸º</em>$o(\log_{1-m/M}\frac{\epsilon}{f(x_0)-f(x^\star)})$ã€‚</p><p>å¯¹$l(\theta)$æ²¡æœ‰ä»»ä½•å‡è®¾çš„æƒ…å†µä¸‹ï¼Œè®¾$\theta^\star$ä½¿$l(\theta)$å–å¾—æœ€å°å€¼ï¼Œæœ‰ï¼š</p>$$
l(\theta_{k+1})-l(\theta^\star)
=\left\{l(\theta_k)-\alpha\nabla l(\theta_k)^T\nabla l(\theta_k)+\frac{\alpha^2}{2}\nabla l(\theta_k)^T\nabla^2 l(c)\nabla l(\theta_k)\right\}-l(\theta^\star),
$$<p>è¿™é‡Œ$c$æ˜¯$\theta_k$å’Œ$\theta_{k+1}$çº¿æ®µä¸Šä¸€ç‚¹ã€‚å¦‚æœ$\nabla^2l(c)\rightarrow\infty$ï¼Œåˆ™$\forall \alpha > 0, l(\theta_{k+1})-l(\theta^\star) >l(\theta_k)-l(\theta^\star)$ï¼Œå› æ­¤ç¬¬$k$æ­¥è¿­ä»£å¹¶æ²¡æœ‰é™ä½æŸå¤±ã€‚æˆ‘ä»¬å¯ä»¥æ„é€ ä¸€ä¸ªå‡½æ•°ï¼Œä½¿å¾—ä»æŸä¸ªèµ·ç‚¹$\theta_0$å¼€å§‹ï¼Œæ¯ä¸€æ­¥æ¢¯åº¦ä¸‹é™éƒ½æ˜¯å‘æ•£çš„ã€‚å› æ­¤æˆ‘ä»¬éœ€è¦é™åˆ¶$\nabla^2l(\theta)\preceq MI$ï¼Œå³$l(\theta)$æ˜¯$M$-Lipschitz smoothçš„ã€‚ä»£å…¥smoothæ¡ä»¶æœ‰</p>$$
l(\theta_{k+1})-l(\theta^\star)
\leq\left\{\frac{\alpha^2M}{2}-\alpha\right\}\|\nabla l(\theta_k)\|^2+l(\theta_k)-l(\theta^\star),
$$<p>ç­‰å¼å³ä¾§å¯¹$\alpha$æ±‚æœ€å°ï¼Œå¾—$\alpha=1/M$æ—¶</p>$$
l(\theta_{k+1})-l(\theta^\star)
\leq -\frac{1}{2M}\left\|\nabla l(\theta_k)\right\|^2+l(\theta_k)-l(\theta^\star).
$$<p>å› æ­¤å½“$0 &lt; \alpha &lt; 2/M$æ—¶ï¼Œæˆ‘ä»¬éƒ½æœ‰$l(\theta_{k+1}) - l(\theta^\star) &lt; l(\theta_k) - l(\theta^\star)$ã€‚</p><p><strong>è¦ç»™å‡ºæ”¶æ•›é€Ÿåº¦éœ€è¦å¯¹</strong>$|\nabla l(\theta_k)|$<strong>ç»™å‡ºä¸‹ç•Œ</strong>ã€‚</p><h4 id=convexæƒ…å½¢>Convexæƒ…å½¢</h4>$$
\begin{align}
&l(\theta^\star)\geq l(\theta_k)+\nabla l(\theta_k)^T(\theta^\star-\theta_k)\\
\Rightarrow~~& l(\theta_k)-l(\theta^\star)\leq\left\|\nabla l(\theta_k)^T(\theta^\star-\theta_k)\right\|\\
&~~~~~~~~~~~~~~~~~~~~~\leq\left\|\nabla l(\theta_k)\right\|\left\|\theta_k-\theta^\star\right\|\\
&~~~~~~~~~~~~~~~~~~~~~\leq\left\|\nabla l(\theta_k)\right\|\left\|\theta_0-\theta^\star\right\|\\
\Leftrightarrow~~&\|\nabla l(\theta_k)\|\geq\frac{l(\theta_k)-l(\theta^\star)}{\left\|\theta_0-\theta^\star\right\|}
\end{align}
$$<p>è®°$\eta_k=l(\theta_k)-l(\theta^\star)$ï¼Œå¹¶å‡è®¾$|\theta_0-\theta^\star|\leq R$ï¼Œæœ‰</p>$$
\begin{align}
\eta_{k+1} &\leq \eta_k - \frac{1}{2M}\|\nabla l(\theta_k)\|^2\\
&\leq\eta_k-\frac{\eta_k^2}{2MR^2}
\end{align}
$$<p>åŒ–ç®€æ–¹å¼æ˜¯ä¸¤è¾¹é™¤ä»¥$\eta_k\eta_{k+1}$ï¼Œæ•´ç†å¾—</p>$$
\begin{align}
&\frac{1}{\eta_{k+1}}-\frac{1}{\eta_k}\geq\frac{1}{2MR^2}\frac{\eta_k}{\eta_{k+1}}\geq\frac{1}{2MR^2}\\
\Rightarrow~~&\sum_{i=0}^k\frac{1}{\eta_{i+1}}-\frac{1}{\eta_i}=\frac{1}{\eta_{k+1}}-\frac{1}{\eta_0}\geq\frac{k+1}{2MR^2},
\end{align}
$$<p>å³</p>$$
l(\theta_k)-l(\theta^\star)=\eta_k\leq\frac{2MR^2}{k},
$$<p>å› æ­¤æ”¶æ•›é€Ÿåº¦æ˜¯$O(1/k)$çº§åˆ«çš„æ¬¡çº¿æ€§æ”¶æ•›ã€‚</p><h4 id=m-strongly-convexæƒ…å½¢>$m$-strongly convexæƒ…å½¢</h4><p>æ ¹æ®å¼ºå‡¸å®šä¹‰ï¼ˆå‚è€ƒLipschitz smoothçš„å‡ ç§å®šä¹‰ç›¸äº’çš„æ¨å¯¼ï¼‰ï¼š</p>$$
\|\nabla l(\theta_k)\|^2 \geq 2m\left(l(\theta_k)-l(\theta^\star)\right)
$$<p>ä»£å…¥ä¸‹ç•Œæœ‰</p>$$
l(\theta_k)-l(\theta^\star)=\eta_k\leq\left(1-\frac{m}{M}\right)^k\eta_0
$$<h3 id=stochastic-gradient-descent>Stochastic Gradient Descent</h3><p>éšæœºæƒ…å½¢ä¸‹ï¼Œå‡è®¾$l(\theta)$ä¸ºå‡¸ï¼Œè®°$\theta$å¤„çš„å¸¦å™ªæ¬¡æ¢¯åº¦ä¸º$\tilde g_{\theta}$ï¼Œå¹¶ä¸”$\exists B>0, \forall \theta\in\Theta, \mathbb{E}[\left|\tilde g_\theta\right|^2|\theta]\leq B^2$ï¼Œä¸”å‡è®¾å‚æ•°ç©ºé—´æœ‰ç•Œï¼Œå³$\forall \theta \in \Theta, |\theta|\leq r$ã€‚è€ƒè™‘ä¸€èˆ¬çš„éšæœºæ¢¯åº¦ä¸‹é™ï¼Œå³æ›´æ–°åå¯èƒ½è½åœ¨å¯è¡ŒåŸŸå¤–ï¼Œé€šè¿‡æŠ•å½±å¾—åˆ°æ–°çš„å‚æ•°ä¼°è®¡ï¼š</p>$$
\theta_{k+1} = Proj_\Theta(\theta_k-\alpha \tilde g_{\theta_k})ï¼Œ
$$<p>å› ä¸ºæŠ•å½±åçš„å‘é‡è·ç¦»$\Theta$ä¸­çš„ä»»æ„å‘é‡æ›´è¿‘ï¼Œæœ‰</p>$$
\begin{align}
\|\theta_{k+1}-\theta^\star\|^2 &\leq \|\theta_k-\alpha\tilde g_{\theta_k} -\theta^\star\|^2 \\
&=\|\theta_k-\theta^\star\|^2 + \alpha^2\|\tilde g_{\theta_k}\|^2-2\alpha\tilde g_{\theta_k}^T(\theta_k-\theta^\star)
\end{align}
$$<p>æ³¨æ„åˆ°è¿™ä¸ªå¼å­ä¸­æœ‰ä¸¤ä¸ªéšæœºå˜é‡$\theta_k$å’Œ$\tilde g_{\theta_k}$ï¼Œåè€…ä¾èµ–å‰è€…ã€‚å› æ­¤æˆ‘ä»¬è¿™é‡Œå¯¹$\tilde g_{\theta_k}$åœ¨ç»™å®š$\theta_k$çš„æƒ…å†µä¸‹æ±‚æœŸæœ›ï¼š</p>$$
\begin{align}
\mathbb{E}_{\tilde g_{\theta_k}}[\|\theta_{k+1}-\theta^\star\|^2|\theta_k] &\leq \|\theta_k-\theta^\star\|^2+ \alpha^2\mathbb{E}[\|\tilde g_{\theta_k}\|^2|\theta_k] - 2\alpha (\theta_k-\theta^\star)^T g_{\theta_k}\\
&\leq \|\theta_k-\theta^\star\|^2+ \alpha^2B^2 - 2\alpha (\theta_k-\theta^\star)^T g_{\theta_k}\\
\end{align}
$$<h4 id=convexæƒ…å½¢-1>Convexæƒ…å½¢</h4><p>åˆ©ç”¨å‡½æ•°çš„å‡¸æ€§ï¼Œæœ‰</p>$$
\mathbb{E}_{\tilde g_{\theta_k}}[\|\theta_{k+1}-\theta^\star\|^2|\theta_k] \leq \|\theta_k-\theta^\star\|^2+ \alpha^2B^2 - 2\alpha \{l(\theta_k)-l(\theta^\star)\}
$$<p>å†å¯¹$\theta_k$æ±‚æœŸæœ›ï¼Œåˆ™ä¹‹åæ‰€æœ‰çš„æœŸæœ›éƒ½æ˜¯å¯¹$\tilde g_{\theta_k}$å’Œ$\theta_k$æ±‚çš„è”åˆæœŸæœ›ï¼Œå› æ­¤ä¸‹æ ‡ä¹‹åçœç•¥ã€‚è®°$\gamma_k = \mathbb{E}[|\theta_{k}-\theta^\star|^2]$ï¼Œæ•´ç†æœ‰</p>$$
\begin{align}
& \mathbb{E}[l(\theta_k)] - l(\theta^\star) \leq \frac{1}{2\alpha} (\gamma_k-\gamma_{k+1}) + \frac{\alpha B^2}{2}\\
\Rightarrow~~& \sum_{i=0}^k\left\{\mathbb{E}[l(\theta_k)]-l(\theta^\star)\right\} \leq \frac{1}{2\alpha}(\gamma_0-\gamma_{k+1}) + \frac{(k+1)\alpha B^2}{2}\\
&~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\leq \frac{r^2}{2\alpha} + \frac{(k+1)\alpha B^2}{2}
\end{align}
$$<p>åˆ©ç”¨$\min$å‡½æ•°çš„å‡¹æ€§ï¼Œå¹¶è®°$k$æ¬¡è¿­ä»£ä¸­æœ€å¥½çš„å‚æ•°ä¸º$\theta_{best}$</p>$$
\begin{align}
\sum_{i=0}^k\left\{\mathbb{E}[l(\theta_k)]-l(\theta^\star)\right\} &\geq (k+1)\left\{\min_{i=0,\dots,k}\mathbb{E}[l(\theta_i)]-l(\theta^\star)\right\} \\
&\geq (k+1)\left\{\mathbb{E}[\min_{i=0,\dots,k}l(\theta_i)] - l(\theta^\star)\right\} \\
& = (k+1)\left\{\mathbb{E}[l(\theta_{best})]-l(\theta^\star)\right\}
\end{align}
$$<p>æœ€åä¸ç­‰å¼å³è¾¹å¯¹$\alpha$æ±‚æœ€å°ï¼Œæ•´ç†å¾—</p>$$
\mathbb{E}[l(\theta_{best})] - l(\theta^\star) \leq \frac{Br}{\sqrt{k}}
$$<h4 id=strong-convexæƒ…å½¢>Strong Convexæƒ…å½¢</h4><p>å¼ºå‡¸æƒ…å½¢ä¸‹ç”¨å¸¸æ•°æ­¥é•¿$\alpha$å…ˆæŠŠ$k$ä¸ªå¼å­åŠ èµ·æ¥å†å–æœ€ä¼˜çš„$\alpha^\star$å¹¶ä¸èƒ½è¾¾åˆ°æœ€ä¼˜çš„æ”¶æ•›ç•Œã€‚ä¸ºäº†ä½¿å¾—ä¸Šç•Œæ›´ç´§ï¼Œæˆ‘ä»¬å…è®¸æ­¥é•¿å¯å˜ï¼Œå³æ¯ä¸€æ­¥æœ‰ä¸€ä¸ªæ­¥é•¿$\alpha_k$ï¼Œç„¶åå¯¹æ¯ä¸ªå¼å­éƒ½å–ä¸€ä¸ªç²¾å¿ƒæ„é€ çš„æ­¥é•¿ï¼Œæœ€åè¾¾åˆ°$O(1/K)$çš„æ”¶æ•›ã€‚åˆ©ç”¨å¼ºå‡¸æœ‰</p>$$
\mathbb{E}_{\tilde g_{\theta_k}}[\|\theta_{k+1}-\theta^\star\|^2]\leq(1-\alpha_k m)\|\theta_k-\theta^\star\|^2 + \alpha_k^2B^2-2\alpha\{l(\theta_k)-l(\theta^\star)\}
$$<p>æˆ‘ä»¬è¿™é‡Œä¸èƒ½å¯¹$\alpha_k$ç›´æ¥å–æœ€ä¼˜ï¼Œå› ä¸ºæœ€ä¼˜å€¼ä¾èµ–äº$|\theta_k-\theta^\star|^2$ï¼Œè€Œæˆ‘ä»¬ä¸çŸ¥é“$\theta^\star$çš„å…·ä½“å€¼ã€‚è¿™é‡Œ<strong>éå¸¸ç²¾å¦™</strong>åœ°æ„é€ äº†ä¸€ä¸ªæ­¥é•¿$\alpha_k=1/km$ï¼Œæˆ‘è¿˜æ²¡å¼„æ‡‚æ€ä¹ˆæƒ³åˆ°è¿™æ ·å–çš„ã€‚Anywayï¼Œä»£å…¥æ­¥é•¿ï¼Œå¯¹$\theta_k$æ±‚æœŸæœ›å¹¶è®°$\gamma_k=\mathbb{E}[|\theta_k-\theta^\star|^2],\eta_k=\mathbb{E}[l(\theta_k)-l(\theta^\star)]$æœ‰</p>$$
\begin{align}
\eta_k \leq \frac{B^2}{2km} + \frac{(k-1)m\gamma_k}{2} - \frac{km\gamma_{k+1}}{2}
\end{align}
$$<p>æ³¨æ„åˆ°å³è¾¹æœ€åä¸¤é¡¹å¯ä»¥è¢«telescopeæ¶ˆæ‰ã€‚ä¸¤è¾¹ä¹˜ä»¥$k$å¹¶å–telescope sumæœ‰</p>$$
\begin{align}
&k\cdot\eta_k \leq \frac{B^2}{2m} + \frac{k(k-1)m\gamma_k}{2}-\frac{k^2m\gamma_{k+1}}{2}\\
&~~~~~~~~~\leq\frac{B^2}{2m}+\frac{k(k-1)m\gamma_k}{2}-\frac{(k+1)km\gamma_{k+1}}{2}\\
\Rightarrow~~&\sum_{i=1}^{k}i\cdot\eta_i \leq \frac{B^2k}{2m}+ 0 -\frac{(k+1)km\gamma_{k+1}}{2}
\end{align}
$$<p>å†åˆ©ç”¨ä¹‹å‰çš„æŠ€å·§$\eta_i\geq\min_{j=1,\dots,k}\mathbb{E}[l(\theta_j)]-l(\theta^\star)\geq\mathbb{E}[l(\theta_{best})]-l(\theta^\star)$ï¼Œæœ‰</p>$$
\begin{align}
&\frac{(k+1)k}{2}\cdot\left\{\mathbb{E}[l(\theta_{best})]-l(\theta^\star)\right\} \leq \frac{B^2k}{2m}-\frac{(k+1)km\gamma_{k+1}}{2}\\
\Leftrightarrow~~&\mathbb{E}[l(\theta_{best})]-l(\theta^\star)\leq \frac{B^2}{mk}
\end{align}
$$</section><footer class=article-footer><section class=article-tags><a href=/tags/machine-learning/>Machine Learning</a>
<a href=/tags/math/>Math</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>ç›¸å…³æ–‡ç« </h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84kl%E6%95%A3%E5%BA%A6%E4%BC%B0%E8%AE%A1/><div class=article-image><img src=/p/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84kl%E6%95%A3%E5%BA%A6%E4%BC%B0%E8%AE%A1/cover.b4fff78720d50821465ba154fdc2df26_hu_3b4a1b04b09dd2a6.png width=250 height=150 loading=lazy alt="Featured image of post ä¸€ç§æ–°çš„KLæ•£åº¦ä¼°è®¡" data-hash="md5-tP/3hyDVCCFGW6FU/cLfJg=="></div><div class=article-details><h2 class=article-title>ä¸€ç§æ–°çš„KLæ•£åº¦ä¼°è®¡</h2></div></a></article><article class=has-image><a href=/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/><div class=article-image><img src=/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/cover.14e58351554cfa73826426d3e2e1aace_hu_a47d951a9fa767ee.png width=250 height=150 loading=lazy alt="Featured image of post éšå˜é‡æ¨¡å‹æ€»ç»“" data-hash="md5-FOWDUVVM+nOCZCbT4uGqzg=="></div><div class=article-details><h2 class=article-title>éšå˜é‡æ¨¡å‹æ€»ç»“</h2></div></a></article><article class=has-image><a href=/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/><div class=article-image><img src=/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/cover.84d3b9acd81cdce809bf40d9c86bf4b0_hu_2ec8dbcdde98afbe.png width=250 height=150 loading=lazy alt="Featured image of post ä»æ‹’ç»é‡‡æ ·åˆ°æŠ•æœºæ¨ç†" data-hash="md5-hNO5rNgc3OgJv0DZyGv0sA=="></div><div class=article-details><h2 class=article-title>ä»æ‹’ç»é‡‡æ ·åˆ°æŠ•æœºæ¨ç†</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2025 å¼ æ™—çš„éšç¬”</section><section class=powerby>ä½¿ç”¨ <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> æ„å»º<br>ä¸»é¢˜ <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> ç”± <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> è®¾è®¡</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>
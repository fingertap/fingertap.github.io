<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="最大似然框架下，假设观测变量有缺失或不可观测的属性时，要用到变分的方法。隐变量模型往往是无监督或者少监督模型，因为监督信息可以看做是包含在缺失的隐变量中的一部分。\n注意：\n缺失观测和样本一一对应，而参数则是所有样本共享的。 似然下界的输入是参数和变分分布，梯度回带到参数和分布上。 不可处理（intractable）的分布定义为无法计算，且无法求导。 假设输入$(x, z)\\in\\mathcal{D}=\\mathcal{X}\\times\\mathcal{Z}$中$\\mathcal{Z}$空间是无法观测到的，那么我们的目标就变为了最大化对数边缘似然\n$$ \\tag{1} \\max_{\\theta\\in\\Theta}\\log\\mathcal{L}(\\theta;\\mathbf{X})=\\sum_{x\\in\\mathbf{X}}\\log p_\\theta(x)=\\sum_{x\\in\\mathbf{X}}\\log\\sum_{z\\in\\mathcal{Z}}p_{\\theta}(x, z), $$其中$\\mathbf{X}\\subset\\mathcal{X}$是观测到的数据集。\nEM算法 直接在式子$(1)$中对$\\theta$求导是不好计算的，因为$\\log$中有求和。EM算法的思路是优化$(1)$的下界，其核心假设是$p_\\theta(x, z)$是很好处理的。利用$\\log$函数的凹性和Jensen不等式：\n$$ \\tag{2} \\log\\sum_{z\\in\\mathcal{Z}}p_{\\theta}(x, z) = \\log\\sum_{z\\in\\mathcal{Z}}\\frac{p_{\\theta}(x, z)}{q(z)}q(z) \\geq \\sum_{z\\in\\mathcal{Z}}q(z)\\left\\{\\log p_\\theta(x, z)-\\log q(z)\\right\\}, $$其中$q(z)$是任意定义在$\\mathcal{Z}$上的概率密度函数，且$\\forall z \\in \\mathcal{Z} q(z) > 0$。因此之后优化下界\n$$ \\max_\\theta\\hat{\\mathcal{L}}(q, \\theta;\\mathbf{X})=\\sum_{x\\in\\mathcal{X}}\\sum_{z\\in\\mathcal{Z}}q(z)\\left\\{\\log p_\\theta(x, z)-\\log q(z)\\right\\}. $$这个下界是一个双变量的泛函，一个变量是概率密度$q$，一个变量是参数$\\theta$。采用坐标梯度法，交替寻找当前最优的$q$和$\\theta$即为EM算法。对$q$取最大要求$(2)$式中等号成立，即要求$\\forall z \\in \\mathcal{Z}, p_\\theta(x, z)/q(z)=C$，$C$为某一常数，简单计算一下能得到$C = p_\\theta(x)$，而\n$$ \\tag{E step} q^\\star(z)=p_{\\theta}(z|x) $$而我们在M步时往往会遇到$\\sum_zq(z)\\cdot z$这样的$z$的期望形式，因此在实际实现中，我们往往在内存里记录隐变量的期望\n$$ \\tag{E step in practice} \\mathbb{E}[z] = \\sum_{z\\in\\mathcal{Z}}p_\\theta(z|x)\\cdot z $$这也是E步名字的由来。M步得名原因是我们在这一步里对$\\theta$求了最大，注意这个下界往往是凹的（大部分模型是对数凹的，比如GMM中的高斯分布等指数族分布），因此更新的方式为\n$$ \\tag{M step} \\theta^{new} = \\arg\\max_\\theta\\sum_{z\\in\\mathcal{Z}}p_{\\theta^{old}}(z|x)\\log p_\\theta(x, z) $$表示成概率图是这样：\n"><title>隐变量模型总结</title>
<link rel=canonical href=https://fingertap.github.io/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/><link rel=stylesheet href=/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="隐变量模型总结"><meta property='og:description' content="最大似然框架下，假设观测变量有缺失或不可观测的属性时，要用到变分的方法。隐变量模型往往是无监督或者少监督模型，因为监督信息可以看做是包含在缺失的隐变量中的一部分。\n注意：\n缺失观测和样本一一对应，而参数则是所有样本共享的。 似然下界的输入是参数和变分分布，梯度回带到参数和分布上。 不可处理（intractable）的分布定义为无法计算，且无法求导。 假设输入$(x, z)\\in\\mathcal{D}=\\mathcal{X}\\times\\mathcal{Z}$中$\\mathcal{Z}$空间是无法观测到的，那么我们的目标就变为了最大化对数边缘似然\n$$ \\tag{1} \\max_{\\theta\\in\\Theta}\\log\\mathcal{L}(\\theta;\\mathbf{X})=\\sum_{x\\in\\mathbf{X}}\\log p_\\theta(x)=\\sum_{x\\in\\mathbf{X}}\\log\\sum_{z\\in\\mathcal{Z}}p_{\\theta}(x, z), $$其中$\\mathbf{X}\\subset\\mathcal{X}$是观测到的数据集。\nEM算法 直接在式子$(1)$中对$\\theta$求导是不好计算的，因为$\\log$中有求和。EM算法的思路是优化$(1)$的下界，其核心假设是$p_\\theta(x, z)$是很好处理的。利用$\\log$函数的凹性和Jensen不等式：\n$$ \\tag{2} \\log\\sum_{z\\in\\mathcal{Z}}p_{\\theta}(x, z) = \\log\\sum_{z\\in\\mathcal{Z}}\\frac{p_{\\theta}(x, z)}{q(z)}q(z) \\geq \\sum_{z\\in\\mathcal{Z}}q(z)\\left\\{\\log p_\\theta(x, z)-\\log q(z)\\right\\}, $$其中$q(z)$是任意定义在$\\mathcal{Z}$上的概率密度函数，且$\\forall z \\in \\mathcal{Z} q(z) > 0$。因此之后优化下界\n$$ \\max_\\theta\\hat{\\mathcal{L}}(q, \\theta;\\mathbf{X})=\\sum_{x\\in\\mathcal{X}}\\sum_{z\\in\\mathcal{Z}}q(z)\\left\\{\\log p_\\theta(x, z)-\\log q(z)\\right\\}. $$这个下界是一个双变量的泛函，一个变量是概率密度$q$，一个变量是参数$\\theta$。采用坐标梯度法，交替寻找当前最优的$q$和$\\theta$即为EM算法。对$q$取最大要求$(2)$式中等号成立，即要求$\\forall z \\in \\mathcal{Z}, p_\\theta(x, z)/q(z)=C$，$C$为某一常数，简单计算一下能得到$C = p_\\theta(x)$，而\n$$ \\tag{E step} q^\\star(z)=p_{\\theta}(z|x) $$而我们在M步时往往会遇到$\\sum_zq(z)\\cdot z$这样的$z$的期望形式，因此在实际实现中，我们往往在内存里记录隐变量的期望\n$$ \\tag{E step in practice} \\mathbb{E}[z] = \\sum_{z\\in\\mathcal{Z}}p_\\theta(z|x)\\cdot z $$这也是E步名字的由来。M步得名原因是我们在这一步里对$\\theta$求了最大，注意这个下界往往是凹的（大部分模型是对数凹的，比如GMM中的高斯分布等指数族分布），因此更新的方式为\n$$ \\tag{M step} \\theta^{new} = \\arg\\max_\\theta\\sum_{z\\in\\mathcal{Z}}p_{\\theta^{old}}(z|x)\\log p_\\theta(x, z) $$表示成概率图是这样：\n"><meta property='og:url' content='https://fingertap.github.io/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/'><meta property='og:site_name' content='张晗的随笔'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='Machine Learning'><meta property='article:tag' content='Bayesian'><meta property='article:tag' content='Math'><meta property='article:published_time' content='2019-07-01T00:02:20+08:00'><meta property='article:modified_time' content='2019-07-01T00:02:20+08:00'><meta property='og:image' content='https://fingertap.github.io/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/cover.png'><meta name=twitter:title content="隐变量模型总结"><meta name=twitter:description content="最大似然框架下，假设观测变量有缺失或不可观测的属性时，要用到变分的方法。隐变量模型往往是无监督或者少监督模型，因为监督信息可以看做是包含在缺失的隐变量中的一部分。\n注意：\n缺失观测和样本一一对应，而参数则是所有样本共享的。 似然下界的输入是参数和变分分布，梯度回带到参数和分布上。 不可处理（intractable）的分布定义为无法计算，且无法求导。 假设输入$(x, z)\\in\\mathcal{D}=\\mathcal{X}\\times\\mathcal{Z}$中$\\mathcal{Z}$空间是无法观测到的，那么我们的目标就变为了最大化对数边缘似然\n$$ \\tag{1} \\max_{\\theta\\in\\Theta}\\log\\mathcal{L}(\\theta;\\mathbf{X})=\\sum_{x\\in\\mathbf{X}}\\log p_\\theta(x)=\\sum_{x\\in\\mathbf{X}}\\log\\sum_{z\\in\\mathcal{Z}}p_{\\theta}(x, z), $$其中$\\mathbf{X}\\subset\\mathcal{X}$是观测到的数据集。\nEM算法 直接在式子$(1)$中对$\\theta$求导是不好计算的，因为$\\log$中有求和。EM算法的思路是优化$(1)$的下界，其核心假设是$p_\\theta(x, z)$是很好处理的。利用$\\log$函数的凹性和Jensen不等式：\n$$ \\tag{2} \\log\\sum_{z\\in\\mathcal{Z}}p_{\\theta}(x, z) = \\log\\sum_{z\\in\\mathcal{Z}}\\frac{p_{\\theta}(x, z)}{q(z)}q(z) \\geq \\sum_{z\\in\\mathcal{Z}}q(z)\\left\\{\\log p_\\theta(x, z)-\\log q(z)\\right\\}, $$其中$q(z)$是任意定义在$\\mathcal{Z}$上的概率密度函数，且$\\forall z \\in \\mathcal{Z} q(z) > 0$。因此之后优化下界\n$$ \\max_\\theta\\hat{\\mathcal{L}}(q, \\theta;\\mathbf{X})=\\sum_{x\\in\\mathcal{X}}\\sum_{z\\in\\mathcal{Z}}q(z)\\left\\{\\log p_\\theta(x, z)-\\log q(z)\\right\\}. $$这个下界是一个双变量的泛函，一个变量是概率密度$q$，一个变量是参数$\\theta$。采用坐标梯度法，交替寻找当前最优的$q$和$\\theta$即为EM算法。对$q$取最大要求$(2)$式中等号成立，即要求$\\forall z \\in \\mathcal{Z}, p_\\theta(x, z)/q(z)=C$，$C$为某一常数，简单计算一下能得到$C = p_\\theta(x)$，而\n$$ \\tag{E step} q^\\star(z)=p_{\\theta}(z|x) $$而我们在M步时往往会遇到$\\sum_zq(z)\\cdot z$这样的$z$的期望形式，因此在实际实现中，我们往往在内存里记录隐变量的期望\n$$ \\tag{E step in practice} \\mathbb{E}[z] = \\sum_{z\\in\\mathcal{Z}}p_\\theta(z|x)\\cdot z $$这也是E步名字的由来。M步得名原因是我们在这一步里对$\\theta$求了最大，注意这个下界往往是凹的（大部分模型是对数凹的，比如GMM中的高斯分布等指数族分布），因此更新的方式为\n$$ \\tag{M step} \\theta^{new} = \\arg\\max_\\theta\\sum_{z\\in\\mathcal{Z}}p_{\\theta^{old}}(z|x)\\log p_\\theta(x, z) $$表示成概率图是这样：\n"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://fingertap.github.io/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/cover.png'><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_ce70c8f8535541a2.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🇨🇳</span></figure><div class=site-meta><h1 class=site-name><a href=/>张晗的随笔</a></h1><h2 class=site-description>看风景 > 爬上山顶</h2></div></header><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/about-me/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>About Me</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#em算法>EM算法</a></li><li><a href=#变分em>变分EM</a></li><li><a href=#vae>VAE</a><ol><li><a href=#monte-carlo-gradient-estimator>Monte Carlo gradient estimator</a></li><li><a href=#reparameterization-trick-sgvb-estimator>Reparameterization trick (SGVB estimator)</a></li><li><a href=#second-version-sgvb-estimator>Second Version SGVB estimator</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/><img src=/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/cover_hu_4aceb241f2dfc9a4.png srcset="/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/cover_hu_4aceb241f2dfc9a4.png 800w, /p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/cover_hu_c22a5e1c2e92640c.png 1600w" width=800 height=800 loading=lazy alt="Featured image of post 隐变量模型总结"></a></div><div class=article-details><header class=article-category><a href=/categories/machine-learning/>Machine Learning</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/>隐变量模型总结</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Jul 01, 2019</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 2 分钟</time></div></footer></div></header><section class=article-content><p>最大似然框架下，假设观测变量有缺失或不可观测的属性时，要用到变分的方法。隐变量模型往往是无监督或者少监督模型，因为监督信息可以看做是包含在缺失的隐变量中的一部分。</p><p>注意：</p><ol><li>缺失观测和样本一一对应，而参数则是所有样本共享的。</li><li>似然下界的输入是参数和变分分布，梯度回带到参数和分布上。</li><li>不可处理（intractable）的分布定义为无法计算，且无法求导。</li></ol><p>假设输入$(x, z)\in\mathcal{D}=\mathcal{X}\times\mathcal{Z}$中$\mathcal{Z}$空间是无法观测到的，那么我们的目标就变为了最大化对数边缘似然</p>$$
\tag{1}
\max_{\theta\in\Theta}\log\mathcal{L}(\theta;\mathbf{X})=\sum_{x\in\mathbf{X}}\log p_\theta(x)=\sum_{x\in\mathbf{X}}\log\sum_{z\in\mathcal{Z}}p_{\theta}(x, z),
$$<p>其中$\mathbf{X}\subset\mathcal{X}$是观测到的数据集。</p><h2 id=em算法>EM算法</h2><p>直接在式子$(1)$中对$\theta$求导是不好计算的，因为$\log$中有求和。EM算法的思路是优化$(1)$的下界，<strong>其核心假设是$p_\theta(x, z)$是很好处理的</strong>。利用$\log$函数的凹性和Jensen不等式：</p>$$
\tag{2}
\log\sum_{z\in\mathcal{Z}}p_{\theta}(x, z) = \log\sum_{z\in\mathcal{Z}}\frac{p_{\theta}(x, z)}{q(z)}q(z) \geq \sum_{z\in\mathcal{Z}}q(z)\left\{\log p_\theta(x, z)-\log q(z)\right\},
$$<p>其中$q(z)$是任意定义在$\mathcal{Z}$上的概率密度函数，且$\forall z \in \mathcal{Z} q(z) > 0$。因此之后优化下界</p>$$
\max_\theta\hat{\mathcal{L}}(q, \theta;\mathbf{X})=\sum_{x\in\mathcal{X}}\sum_{z\in\mathcal{Z}}q(z)\left\{\log p_\theta(x, z)-\log q(z)\right\}.
$$<p>这个下界是一个双变量的泛函，一个变量是概率密度$q$，一个变量是参数$\theta$。采用坐标梯度法，交替寻找当前最优的$q$和$\theta$即为EM算法。对$q$取最大要求$(2)$式中等号成立，即要求$\forall z \in \mathcal{Z}, p_\theta(x, z)/q(z)=C$，$C$为某一常数，简单计算一下能得到$C = p_\theta(x)$，而</p>$$
\tag{E step}
q^\star(z)=p_{\theta}(z|x)
$$<p>而我们在M步时往往会遇到$\sum_zq(z)\cdot z$这样的$z$的期望形式，因此在实际实现中，我们往往在内存里记录隐变量的期望</p>$$
\tag{E step in practice}
\mathbb{E}[z] = \sum_{z\in\mathcal{Z}}p_\theta(z|x)\cdot z
$$<p>这也是E步名字的由来。M步得名原因是我们在这一步里对$\theta$求了最大，注意这个下界往往是凹的（大部分模型是对数凹的，比如GMM中的高斯分布等指数族分布），因此更新的方式为</p>$$
\tag{M step}
\theta^{new} = \arg\max_\theta\sum_{z\in\mathcal{Z}}p_{\theta^{old}}(z|x)\log p_\theta(x, z)
$$<p>表示成概率图是这样：</p><p><img src=/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/EM_pgm.jpg width=1710 height=848 srcset="/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/EM_pgm_hu_37689ea88cea9b39.jpg 480w, /p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/EM_pgm_hu_3269574e2543dda0.jpg 1024w" loading=lazy alt="PGM for EM algorithm" class=gallery-image data-flex-grow=201 data-flex-basis=483px></p><h2 id=变分em>变分EM</h2><p>变分EM是为了处理全贝叶斯情形下对参数、隐变量的多重积分不可求的问题而发明的。变分（variational）意味着我们要近似一个函数，在一族函数中找一个最能近似目标的。EM算法中的$q(z)$即为一个变分分布，用以近似真实的隐变量后验分布$p_\theta(z|x)$，而变分EM甚至需要对$q(z)$做进一步的近似。</p><p>EM算法假设我们有参数$\theta$和隐变量$z$要估计。特别地，对于参数$\theta$我们做的是点估计，是最大似然或者最大后验推断。但是在全贝叶斯方法中，我们对$\theta$也会引入先验分布$p(\theta|\alpha)$，并积分掉$\theta$（$\alpha$是超参）。也即现在我们的目标是</p>$$
\max_\alpha \int p(x|\theta)p(\theta|\alpha) d\theta=\int\int p(x, z|\theta)p(\theta|\alpha)d\theta dz
$$<p>我们可以把$\theta$吸收到$z$中，形式上其实和$(2)$一致。即便我们用一个变分分布$q(z, \theta)$来近似$p_\alpha(z, \theta|x)$，在EM算法中往往也会涉及到intractable的积分。一个思路是采样这样的积分，用MCMC方法的思路，这样做的缺点是对每个样本都要做一次采样，对于大数据集计算开销相当大。另一种方法是解耦合这样可以分组的隐变量。</p><p>我们假设$q(z, \theta) = q(z)q(\theta)$，或者更一般地，假设$q(z) = \prod_i q_i(z_i)$，即每组隐变量有自己的变分分布且相互独立。假设这样分解以后，对于每个隐变量组$q_i(z_i)$都是tractable的，记$q_i=q_i(z_i)$，单独提取出$z_j$观察下界$\hat{\mathcal{L}}$有</p>$$
\begin{align}
\hat{\mathcal{L}(q)} &= \int \prod_i q_i \left\{\log p(x, z)-\sum_i\log q_i\right\}dz \\
&=\int \prod_i q_i\log p(x, z)dz-\int\prod_iq_i\sum_{i'}\log q_{i'} dz \\
&=\int q_j\left\{\int\log p(x, z)\prod_{i\neq j}q_i dz_i \right\}dz_j - \int \prod_{i} q_i\log q_jdz + \int \prod_i q_i\sum_{i'\neq j}\log q_{i'} dz\\
&= \int q_j \mathbb{E}_{i\neq j}[\log p(x, z)]dz_j - \int q_j\log q_jdz_j + const
\end{align}
$$<p>把右侧看做一个KL散度，最优的$q_j$满足</p>$$
\tag{Variational EM}
\log q_j^\star(z_j) = \mathbb{E}_{i\neq j}[\log p(x, z)]
$$<p>注意到更新$z_j$的分布需要用到$i\neq j$的所有分布来算$p(x, z)$，因此不同的隐变量组的更新是相互依赖的。变分EM迭代地固定$i\neq j$来更新某个隐变量$z_j$，直至所有的隐变量组分布收敛。概率图如下：</p><p><img src=/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/variational_EM_pgm.jpg width=1236 height=936 srcset="/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/variational_EM_pgm_hu_8a48df77f773ec61.jpg 480w, /p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/variational_EM_pgm_hu_cc478040d61e440e.jpg 1024w" loading=lazy alt="PGM for variational EM" class=gallery-image data-flex-grow=132 data-flex-basis=316px></p><h2 id=vae>VAE</h2><p>变分自编码器（Variational Auto Encoder）也是隐变量的intractability带来的，不同之处是VAE进一步假设，$p_\theta(x, z), p_{\theta}(z|x)$都是intractable的，且变分将$z$分组也不能使得分布变为tractable的，这样的情形是存在的，比如非线性神经网络。因此我们需要更好的变分方式来近似$p_\theta(z|x)$。VAE提出的方案是用一个由$\phi$控制的分布$q_\phi(z|x)$：</p>$$
\begin{align}
\tag{3}
\hat{\mathcal{L}} (\theta, \phi; \mathbf{X}) &= \sum_{x\in\mathcal{X}}\mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x, z)-\log q_\phi(z|x)]\\
&= \sum_{x\in\mathcal{X}}\sum_{z\in\mathcal{Z}}q_\phi(z|x)\left\{\log p_\theta(x|z)+\log p_\theta(z)-\log q_\phi(z|x)\right\} \\
\tag{5}
& = \sum_{x\in\mathcal{X}}\mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)] - \text{KL}\left[q_\phi(z|x)\Vert p_\theta(z)\right]
\end{align}
$$<p>其中$q_\phi(z|x)$被理解为编码器（Encoder），将观测样本映射到隐变量空间$\mathcal{Z}$，$p_\theta(x|z)$为解码器，将隐变量映射回观测样本空间$\mathcal{X}$。</p><p>我们要优化$\hat{\mathcal{L}}$需要对$\theta$和$\phi$求导，其中对$\phi$求导因为期望的存在有几种处理方式。这里看到$\hat{\mathcal{L}}$有$(3)$和$(5)$两种表示，其对$\phi$求导有些问题。</p><h3 id=monte-carlo-gradient-estimator>Monte Carlo gradient estimator</h3><p>一般期望对于分布的参数求导可以使用下面的近似</p>$$
\begin{align}
\nabla_\phi\mathbb{E}_{q_\phi(z)}[f(z)] &= \int f(z) \nabla_\phi q_\phi(z) dz \\
&=\int f(z) q_\phi(z) \frac{\nabla_\phi q_\phi(z)}{q_\phi(z)} dz\\
&=\int f(z)q_\phi(z)\nabla_\phi\log q_\phi(z) dz\\
&=\mathbb{E}_{q_\phi(z)}[f(z)\nabla_\phi\log q_\phi(z)] \\
&\simeq \frac{1}{L}\sum_{l=1}^{L}f(z^{(l)})\nabla_\phi\log q_\phi(z^{(l)})
\end{align}
$$<p>但是这样得到的近似方差很大，需要较大的$L$来保证一个很好的梯度估计（详见<a class=link href=https://icml.cc/2012/papers/687.pdf target=_blank rel=noopener>这篇文章</a>）。在$(3)$中我们可以用类似的方式得到$\hat{\mathcal{L}}$对$\phi$的导数，但是较大的$L$使得每个样本的采样代价高，因此在大数据集上没有办法应用。</p><h3 id=reparameterization-trick-sgvb-estimator>Reparameterization trick (SGVB estimator)</h3><p>对于式$(3)$中的期望，如果我们对$z$节点进行采样近似以后，再算对$\phi$的导数会得到不正确的结果，因为采样的分布$q_\phi(z|x)$是依赖$\phi$的，概率图如下：</p><p><img src=/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/VAE_pgm.jpg width=822 height=758 srcset="/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/VAE_pgm_hu_b4aad4d3cb62f3d9.jpg 480w, /p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/VAE_pgm_hu_cbcbfa9fad28bed6.jpg 1024w" loading=lazy alt="PGM for VAE" class=gallery-image data-flex-grow=108 data-flex-basis=260px></p><p>Reparameterization将随机性的来源从$z$转移到另一个辅助的噪声变量$\epsilon$，假设$z=g_\phi(\epsilon, x)$，其中$\epsilon\sim p(\epsilon)$，$(3)$式变为</p>$$
\begin{align}
\hat{\mathcal{L}}{}^A(\phi, \theta;\mathbf{X}) &= \sum_{x\in\mathcal{X}}\mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x, z)-\log q_\phi(z|x)] \\
&=\sum_{x\in\mathcal{X}}\mathbb{E}_{p(\epsilon)}[\log p_\theta(x, g_\phi(\epsilon, x))-\log q_\phi(g_\phi(\epsilon, x)|x)]\\
&\simeq \sum_{x\in\mathcal{X}}\frac{1}{L}\log p_\theta(x, g_\phi(\epsilon^{(l)}, x))-\log q_\phi(g_\phi(\epsilon^{(l)}, x)|x)
\end{align}
$$<p>这样的近似比MC梯度近似有更小的方差，且我们可以直接对损失函数进行近似。SGVB的概率图如下：</p><p><img src=/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/SGVB_pgm.jpg width=612 height=796 srcset="/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/SGVB_pgm_hu_79e5feb37141ef71.jpg 480w, /p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/SGVB_pgm_hu_dce0890904a768cd.jpg 1024w" loading=lazy alt="PGM for SGVB" class=gallery-image data-flex-grow=76 data-flex-basis=184px></p><h3 id=second-version-sgvb-estimator>Second Version SGVB estimator</h3><p>$(3)$式可以化简为$(5)$式，若$(5)$式中的KL散度项可以积分（tractable），我们就可以只对$(5)$式中的第一项进行采样近似，相比于最原始的SGVB估计子，因为只对变分下界$\hat{\mathcal{L}}$的一部分近似，方差会更小：</p>$$
\hat{\mathcal{L}}{}^B(\phi, \theta; \mathbf{X}) = -\text{KL}\left[q_\phi(z|x)\Vert p_\theta(z)\right] + \frac{1}{L}\sum_{l=1}^L\log p_\theta\left(x\middle|g_\phi(\epsilon^{(l)}, x)\right)
$$<p>最后，整个VAE的过程如下：</p><p><img src=/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/VAE_flowchart.jpg width=1699 height=420 srcset="/p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/VAE_flowchart_hu_d2c23aa8928313f1.jpg 480w, /p/%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/VAE_flowchart_hu_2bd7d9fa74e02e8f.jpg 1024w" loading=lazy alt="VAE flowchart" class=gallery-image data-flex-grow=404 data-flex-basis=970px></p></section><footer class=article-footer><section class=article-tags><a href=/tags/machine-learning/>Machine Learning</a>
<a href=/tags/bayesian/>Bayesian</a>
<a href=/tags/math/>Math</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84kl%E6%95%A3%E5%BA%A6%E4%BC%B0%E8%AE%A1/><div class=article-image><img src=/p/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84kl%E6%95%A3%E5%BA%A6%E4%BC%B0%E8%AE%A1/cover.b4fff78720d50821465ba154fdc2df26_hu_3b4a1b04b09dd2a6.png width=250 height=150 loading=lazy alt="Featured image of post 一种新的KL散度估计" data-hash="md5-tP/3hyDVCCFGW6FU/cLfJg=="></div><div class=article-details><h2 class=article-title>一种新的KL散度估计</h2></div></a></article><article class=has-image><a href=/p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%94%B6%E6%95%9B%E5%88%86%E6%9E%90/><div class=article-image><img src=/p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%94%B6%E6%95%9B%E5%88%86%E6%9E%90/cover.0f792aeaf735d1882c7842d7f7a09182_hu_934424ce9ce33e5a.png width=250 height=150 loading=lazy alt="Featured image of post 梯度下降收敛分析" data-hash="md5-D3kq6vc10YgseELX96CRgg=="></div><div class=article-details><h2 class=article-title>梯度下降收敛分析</h2></div></a></article><article class=has-image><a href=/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/><div class=article-image><img src=/p/%E4%BB%8E%E6%8B%92%E7%BB%9D%E9%87%87%E6%A0%B7%E5%88%B0%E6%8A%95%E6%9C%BA%E6%8E%A8%E7%90%86/cover.84d3b9acd81cdce809bf40d9c86bf4b0_hu_2ec8dbcdde98afbe.png width=250 height=150 loading=lazy alt="Featured image of post 从拒绝采样到投机推理" data-hash="md5-hNO5rNgc3OgJv0DZyGv0sA=="></div><div class=article-details><h2 class=article-title>从拒绝采样到投机推理</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2025 张晗的随笔</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>